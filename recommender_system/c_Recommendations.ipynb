{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry run pip install lightfm==\"1.17\"\n",
    "!poetry run pip install scikit-surprise==\"1.1.3\"\n",
    "# !poetry add recommenders@\"1.1.1\"\n",
    "!poetry run pip install recommenders==\"1.1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import implicit\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "\n",
    "my_seed = 0\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n",
    "from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n",
    "from recommenders.models.deeprec.deeprec_utils import prepare_hparams\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tqdm_to_file = False\n",
    "tqdm_file = \"tqdm_file.txt\"\n",
    "\n",
    "# best_hparams_file = None\n",
    "# evaluation_results_file = None\n",
    "best_hparams_file = '../results/best_hparams_zeegu.csv'\n",
    "evaluation_results_file = '../results/evaluation_results_zeegu.csv'\n",
    "\n",
    "# Specify the datasets we want to use\n",
    "lingorank = True #Zeegu dataset\n",
    "ml_100k = False\n",
    "goodreads = False\n",
    "tomplay = False\n",
    "\n",
    "#Content-based\n",
    "content_based = False\n",
    "\n",
    "#CF\n",
    "als = False\n",
    "als_params = {\n",
    "    'factors': [20,50,100],\n",
    "    'regularization': [0.001, 0.01, 0.05, 0.1],\n",
    "    'alpha': [1,5,10,40,50]\n",
    "}\n",
    "\n",
    "bpr = False\n",
    "bpr_params = {\n",
    "    'factors': [20,50,100],\n",
    "    'regularization': [0.001, 0.01, 0.05, 0.1],\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "    'verify_negative_samples': [True, False]\n",
    "}\n",
    "\n",
    "lmf = False\n",
    "lmf_params = {\n",
    "    'factors': [20,50,100],\n",
    "    'regularization': [0.05, 0.1, 0.5, 0.6, 1],\n",
    "    'learning_rate': [0.05, 0.1, 0.5, 1],\n",
    "    'neg_prop': [10, 30, 50]\n",
    "}\n",
    "\n",
    "cf = als or bpr or lmf # If at least one, we do the CF\n",
    "\n",
    "#LightGCN\n",
    "ada = False\n",
    "bert = False\n",
    "xavier_ada = False\n",
    "xavier_bert = False\n",
    "lightgcn = ada or bert or xavier_ada or xavier_bert # If at least one, we do the LightGCN\n",
    "lightgcn_params = {\n",
    "    'n_layers': [1,2,3,4,5,6,7,8,9,10],\n",
    "    'n': [1,2,3,5,20,30,50],\n",
    "    'lr': [0.0005,0.001,0.01,0.05,0.1]\n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CSVs\n",
    "snapshot_download(\n",
    "    repo_id=\"OloriBern/FLDE\",\n",
    "    allow_patterns=[\"recommendation/*\"],\n",
    "    local_dir=os.path.join(\"..\", \"results\"),\n",
    "    revision=\"main\",\n",
    "    repo_type=\"dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_user_data(group, test_size):\n",
    "        if len(group) == 1:\n",
    "            return pd.DataFrame(), pd.DataFrame(), group\n",
    "        else:\n",
    "            n = max(1, int(round(len(group) * test_size)))\n",
    "            return group.iloc[:-n], group.iloc[-n:], pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, n=None, test_size=0.2, one_core=False):\n",
    "    # Sort by user_id and timestamp\n",
    "    # df.sort_values(by=['user_id', 'timestamp'], ascending=[True, True], inplace=True)\n",
    "\n",
    "    # Sort by user_id and timestamp\n",
    "    df.sort_values(by=['user_id', 'timestamp'], ascending=[True, True], inplace=True)\n",
    "\n",
    "    \n",
    "\n",
    "    tqdm.pandas(desc=\"Splitting data\")\n",
    "    splits = df.groupby('user_id').progress_apply(lambda x: split_user_data(x, test_size))\n",
    "\n",
    "    # Concatenate the results\n",
    "    train_data = pd.concat([split[0] for split in splits])\n",
    "    test_data = pd.concat([split[1] for split in splits])\n",
    "    other_data = pd.concat([split[2] for split in splits])\n",
    "\n",
    "    # Remove other_data from data by checking user_id and item_id\n",
    "    data = pd.concat([train_data, test_data])\n",
    "    # Reset index\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # Find number of articles in test_data but not in train_data\n",
    "    unique_test_articles = set(test_data['item_id'])\n",
    "    unique_train_articles = set(train_data['item_id'])\n",
    "    unique_articles_in_test_not_train = unique_test_articles - unique_train_articles\n",
    "    num_unique_articles_in_test_not_train = len(unique_articles_in_test_not_train)\n",
    "\n",
    "    # Calculate number of unique user_ids in test_data but not in train_data\n",
    "    unique_test_user_ids = set(test_data['user_id'])\n",
    "    unique_train_user_ids = set(train_data['user_id'])\n",
    "    unique_users_in_test_not_train = unique_test_user_ids - unique_train_user_ids\n",
    "    num_unique_users_in_test_not_train = len(unique_users_in_test_not_train)\n",
    "    num_unique_users_in_other_data = len(other_data['user_id'].unique()) if not other_data.empty else 0\n",
    "    num_unique_articles_in_other_data_not_train = len(other_data[~ other_data['item_id'].isin(unique_train_articles)]['item_id'].unique()) if not other_data.empty else 0\n",
    "\n",
    "    print(f\"Number of articles in test_data but not in train_data: {num_unique_articles_in_test_not_train}\")\n",
    "    print(f\"Number of user_ids in test_data but not in train_data: {num_unique_users_in_test_not_train}\")\n",
    "    print(f\"Number of user_ids in other_data: {num_unique_users_in_other_data}\")\n",
    "    print(f\"Number of articles in other_data but not in train_data: {num_unique_articles_in_other_data_not_train}\")\n",
    "\n",
    "    # Calculate size of test data compared to train data\n",
    "    size_test_data = len(test_data)\n",
    "    size_data = len(train_data) + len(test_data)\n",
    "    percentage_test_data = (size_test_data / size_data) * 100\n",
    "\n",
    "    print(f\"Size of test data: {percentage_test_data:.2f}%\")\n",
    "    print(f\"Size of other data: {len(other_data) / size_data * 100:.2f}%\")\n",
    "    print(f\"Size of all test data: {(size_test_data + len(other_data)) / size_data * 100:.2f}%\")\n",
    "    return train_data, test_data, other_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ids(data, train_data, test_data):\n",
    "    # Create mapping for userIds and itemIds based on train_df\n",
    "    unique_user_ids = train_data['user_id'].unique()\n",
    "    unique_item_ids = train_data['item_id'].unique()\n",
    "\n",
    "    user_id_mapping = {userId: i for i, userId in enumerate(unique_user_ids)}\n",
    "    item_id_mapping = {itemId: i for i, itemId in enumerate(unique_item_ids)}\n",
    "\n",
    "    # Map userIds and itemIds in train_df to new consecutive IDs\n",
    "    train_data['mapped_user_id'] = train_data['user_id'].map(user_id_mapping)\n",
    "    train_data['mapped_item_id'] = train_data['item_id'].map(item_id_mapping)\n",
    "\n",
    "    # Function to map new IDs in test_df and update the mapping accordingly\n",
    "    def map_and_update_id(id_value, current_mapping):\n",
    "        if id_value not in current_mapping:\n",
    "            current_mapping[id_value] = max(current_mapping.values()) + 1\n",
    "        return current_mapping[id_value]\n",
    "\n",
    "    test_data['mapped_user_id'] = test_data['user_id'].apply(lambda x: map_and_update_id(x, user_id_mapping))\n",
    "    test_data['mapped_item_id'] = test_data['item_id'].apply(lambda x: map_and_update_id(x, item_id_mapping))\n",
    "\n",
    "    if data is not None:\n",
    "        data['mapped_user_id'] = data['user_id'].map(user_id_mapping).astype('Int64')\n",
    "        data['mapped_item_id'] = data['item_id'].map(item_id_mapping).astype('Int64')\n",
    "    else:\n",
    "        data = pd.concat([train_data, test_data])\n",
    "    \n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    train_data.reset_index(drop=True, inplace=True)\n",
    "    test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data, train_data, test_data, user_id_mapping, item_id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ml_100k():\n",
    "    data = pd.read_csv(\"../results/recommendation/ml-100k/u.data\", sep=\"\\t\", names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "\n",
    "    data = data[data['rating'] >= 4]\n",
    "\n",
    "    # Substract 3 to all the ratings\n",
    "    data['rating'] = data['rating'] - 3\n",
    "\n",
    "    train_data, test_data, other_data = train_test_split(data)\n",
    "    print(f\"ml-100k - Proportion of positive ratings affected to test set: {round(len(test_data)/(len(test_data)+len(train_data))*100,2)} %\")\n",
    "    \n",
    "    data, train_data, test_data, user_id_mapping, item_id_mapping = map_ids(data, train_data, test_data)\n",
    "\n",
    "    # Compute the number of unique users and items and print\n",
    "    num_unique_users = data['mapped_user_id'].nunique()\n",
    "    num_unique_items = data['mapped_item_id'].nunique()\n",
    "    print(f\"Number of unique users: {num_unique_users}\")\n",
    "    print(f\"Number of unique items: {num_unique_items}\")\n",
    "    # Print the number of interactions\n",
    "    print(f\"Number of interactions: {len(data)}\")\n",
    "    # Compute sparsity\n",
    "    sparsity = 1 - len(data) / (num_unique_users * num_unique_items)\n",
    "    print(f\"Sparsity: {sparsity:.2%}\")\n",
    "    ######\n",
    "\n",
    "    ##### Load embeddings #####\n",
    "\n",
    "    items_embeddings = None\n",
    "    if ada or bert or content_based:\n",
    "        items_embeddings = {}\n",
    "        \n",
    "        embeddings_file = f\"../results/recommendation/embeddings_ml-100k.csv.gz\"\n",
    "\n",
    "        embedding_models = {\"ada\": ada, \"bert\": bert}\n",
    "        if content_based:\n",
    "            embedding_models = {\"ada\": True, \"bert\": True}\n",
    "\n",
    "        df = pd.read_csv(embeddings_file)\n",
    "        # Rename movie id to item_id    \n",
    "        df = df.rename(columns={'movie id': 'item_id'})\n",
    "                # Iterate over the dictionary\n",
    "        for embedding_model, is_enabled in embedding_models.items():\n",
    "            if not is_enabled:\n",
    "                continue\n",
    "            embedding_key = embedding_model + \"_embedding\"\n",
    "            assert train_data[train_data['item_id'].isin(df[df[embedding_key].isnull()]['item_id'])].empty \n",
    "            assert test_data[test_data['item_id'].isin(df[df[embedding_key].isnull()]['item_id'])].empty \n",
    "            df2 = df[~ df[embedding_key].isnull()]\n",
    "            df2 = df2.rename(columns={embedding_key: 'embedding'})\n",
    "            df2['embedding'] = df2['embedding'].apply(ast.literal_eval) #Convert list stored as a str to real list type\n",
    "            df2['mapped_item_id'] = df2['item_id'].map(item_id_mapping).astype('Int64')\n",
    "            df2 = df2.dropna(subset=['mapped_item_id']) # If NA, item is not in train set nor test set\n",
    "            items_embeddings[embedding_model] = df2[['item_id', 'mapped_item_id', 'embedding']]\n",
    "\n",
    "\n",
    "    ###########################    \n",
    "    \n",
    "    return {\n",
    "        'data': data,\n",
    "        'train_data': train_data,\n",
    "        'test_data': test_data,\n",
    "        'user_id_mapping': user_id_mapping,\n",
    "        'item_id_mapping': item_id_mapping,\n",
    "        'items_embeddings': items_embeddings\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_LingoRank(strategy: int = 2):\n",
    "    data_full = pd.read_csv(f\"../results/recommendation/Zeegu/strategy{strategy}.csv\")\n",
    "    \n",
    "    # Rename data_full.article_id as data_full.item_id\n",
    "    data_full.rename(columns={\"article_id\": \"item_id\"}, inplace=True)\n",
    "    ## Remove the articles for which there is no positive rating \n",
    "    # Before removing articles, count the unique articles\n",
    "    original_unique_articles = data_full['item_id'].nunique()\n",
    "\n",
    "    # Identify articles that have maximum rating <= 0\n",
    "    articles_to_remove = data_full.groupby('item_id')['rating'].max()\n",
    "    articles_to_remove = articles_to_remove[articles_to_remove <= 0].index.tolist()\n",
    "    articles_to_remove.append(2223234) # Cannot use it for content-based because content is wrong. So we don't consider it at all\n",
    "\n",
    "    # Remove these articles from data_full\n",
    "    data_full = data_full[~data_full['item_id'].isin(articles_to_remove)]\n",
    "\n",
    "    data = data_full[(data_full['rating'] != 0)].copy()\n",
    "    \n",
    "    train_data, test_data, other_data = train_test_split(data)\n",
    "    print(f\"Strategy {strategy} - Proportion of positive ratings affected to test set: {round(len(test_data)/(len(test_data)+len(train_data))*100,2)} %\")\n",
    "\n",
    "    data, train_data, test_data, user_id_mapping, item_id_mapping = map_ids(data, train_data, test_data)\n",
    "\n",
    "    # Compute the number of unique users and items and print\n",
    "    num_unique_users = data['mapped_user_id'].nunique()\n",
    "    num_unique_items = data['mapped_item_id'].nunique()\n",
    "    print(f\"Number of unique users: {num_unique_users}\")\n",
    "    print(f\"Number of unique items: {num_unique_items}\")\n",
    "    # Print the number of interactions\n",
    "    print(f\"Number of interactions: {len(data)}\")\n",
    "    # Compute sparsity\n",
    "    sparsity = 1 - len(data) / (num_unique_users * num_unique_items)\n",
    "    print(f\"Sparsity: {sparsity:.2%}\")\n",
    "\n",
    "\n",
    "    ##### Load embeddings #####\n",
    "\n",
    "    items_embeddings = None\n",
    "    if ada or bert or content_based:\n",
    "        items_embeddings = {}\n",
    "        embeddings_file = f\"../results/recommendation/embeddings_strategy{strategy}.csv.gz\"\n",
    "\n",
    "        embedding_models = {\"ada\": ada, \"bert\": bert}\n",
    "        if content_based:\n",
    "            embedding_models = {\"ada\": True, \"bert\": True}\n",
    "\n",
    "        df = pd.read_csv(embeddings_file)\n",
    "        df = df.rename(columns={'id': 'item_id'})\n",
    "        # Iterate over the dictionary\n",
    "        for embedding_model, is_enabled in embedding_models.items():\n",
    "            if not is_enabled:\n",
    "                continue\n",
    "\n",
    "            embedding_key = embedding_model + \"_embedding\"\n",
    "            # Remove rows for which ada_embedding is null\n",
    "            assert data[data['item_id'].isin(df[df[embedding_key].isnull()]['item_id'])].empty # Already removed the article\n",
    "            assert data_full[data_full['item_id'].isin(df[df[embedding_key].isnull()]['item_id'])].empty # Already removed the article\n",
    "            \n",
    "            df2 = df[~ df[embedding_key].isnull()]\n",
    "            df2 = df2.rename(columns={embedding_key: 'embedding'})\n",
    "            df2['embedding'] = df2['embedding'].apply(ast.literal_eval) #Convert list stored as a str to real list type\n",
    "            df2['mapped_item_id'] = df2['item_id'].map(item_id_mapping).astype('Int64')\n",
    "            df2 = df2.dropna(subset=['mapped_item_id']) # If NA, item is not in train set nor test set\n",
    "            items_embeddings[embedding_model] = df2[['item_id', 'mapped_item_id', 'embedding']]\n",
    "\n",
    "    ###########################\n",
    "\n",
    "    return {\n",
    "            'data': data,\n",
    "            'train_data': train_data,\n",
    "            'test_data': test_data,\n",
    "            'user_id_mapping': user_id_mapping,\n",
    "            'item_id_mapping': item_id_mapping,\n",
    "            'items_embeddings': items_embeddings\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_goodreads(subset: str = \"children\"):\n",
    "\n",
    "    file_path = f'../results/recommendation/Goodreads/goodreads_reviews_{subset}.json.gz'\n",
    "    \n",
    "    # Load the data\n",
    "    data = pd.read_json(file_path, lines=True, compression='gzip')\n",
    "\n",
    "    print(\"JSON LOADED\")\n",
    "\n",
    "    # Select and rename columns\n",
    "    data = data[['user_id', 'book_id', 'rating', 'date_added']]\n",
    "    data.rename(columns={'book_id': 'item_id', 'date_added': 'timestamp'}, inplace=True)\n",
    "\n",
    "    print(\"COLUMNS SELECTED AND RENAMED\")\n",
    "\n",
    "    data = data[data['rating'] >= 4]\n",
    "\n",
    "    # Substract 3 to each rating\n",
    "    data['rating'] = data['rating'] - 3\n",
    "\n",
    "    print(\"RATINGS FILTERED\")\n",
    "\n",
    "    # Convert 'timestamp' column to datetime\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "\n",
    "    print(\"TIMESTAMP CONVERTED\")\n",
    "\n",
    "    unique_user_ids = data['user_id'].unique()\n",
    "    print(f\"Number of users: {len(unique_user_ids)}\")\n",
    "    unique_item_ids = data['item_id'].unique()\n",
    "    print(f\"Number of items: {len(unique_item_ids)}\")\n",
    "\n",
    "    train_data, test_data, other_data = train_test_split(data, test_size=0.2, one_core=True)\n",
    "    print(f\"Goodreads {subset} - Proportion of positive ratings affected to test set: {round(len(test_data)/(len(test_data)+len(train_data))*100,2)} %\")\n",
    "    data, train_data, test_data, user_id_mapping, item_id_mapping = map_ids(data, train_data, test_data)\n",
    "\n",
    "    # Compute the number of unique users and items and print\n",
    "    num_unique_users = data['mapped_user_id'].nunique()\n",
    "    num_unique_items = data['mapped_item_id'].nunique()\n",
    "    print(f\"Number of unique users: {num_unique_users}\")\n",
    "    print(f\"Number of unique items: {num_unique_items}\")\n",
    "    # Print the number of interactions\n",
    "    print(f\"Number of interactions: {len(data)}\")\n",
    "    # Compute sparsity\n",
    "    sparsity = 1 - len(data) / (num_unique_users * num_unique_items)\n",
    "    print(f\"Sparsity: {sparsity:.2%}\")\n",
    "\n",
    "    ##### Load embeddings #####\n",
    "\n",
    "    items_embeddings = None\n",
    "    if ada or bert or content_based:\n",
    "        items_embeddings = {}\n",
    "        \n",
    "        embeddings_file = f\"../results/recommendation/embeddings_goodreads_{subset}.csv.gz\"\n",
    "\n",
    "        embedding_models = {\"ada\": ada, \"bert\": bert}\n",
    "\n",
    "        if content_based:\n",
    "            embedding_models = {\"ada\": True, \"bert\": True}\n",
    "\n",
    "        df = pd.read_csv(embeddings_file)\n",
    "        df = df.rename(columns={'book_id': 'item_id'})\n",
    "        \n",
    "        # Iterate over the dictionary\n",
    "        for embedding_model, is_enabled in embedding_models.items():\n",
    "            if not is_enabled:\n",
    "                continue\n",
    "            embedding_key = embedding_model + \"_embedding\"\n",
    "            assert data[data['item_id'].isin(df[df[embedding_key].isnull()]['item_id'])].empty # Already removed the article\n",
    "            df2 = df[~ df[embedding_key].isnull()]\n",
    "            df2 = df2.rename(columns={embedding_key: 'embedding'})\n",
    "            df2['embedding'] = df2['embedding'].apply(ast.literal_eval) #Convert list stored as a str to real list type\n",
    "            df2['mapped_item_id'] = df2['item_id'].map(item_id_mapping).astype('Int64')\n",
    "            df2 = df2.dropna(subset=['mapped_item_id']) # If NA, item is not in train set nor test set\n",
    "            items_embeddings[embedding_model] = df2[['item_id', 'mapped_item_id', 'embedding']]\n",
    "\n",
    "    ###########################    \n",
    "    \n",
    "    return {\n",
    "        'data': data,\n",
    "        'train_data': train_data,\n",
    "        'test_data': test_data,\n",
    "        'user_id_mapping': user_id_mapping,\n",
    "        'item_id_mapping': item_id_mapping,\n",
    "        'items_embeddings': items_embeddings\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsify_data(data, n_items_per_user):\n",
    "    # Ensure n_items_per_user is at least 1\n",
    "    n_items_per_user = max(1, n_items_per_user)\n",
    "\n",
    "    # Sort data by user and timestamp in descending order (newest first)\n",
    "    sorted_data = data.sort_values(by=['user_id', 'timestamp'], ascending=[True, False])\n",
    "\n",
    "    # Group by user and keep only the newest n_items_per_user items for each user\n",
    "    sparsified_data = sorted_data.groupby('user_id').head(n_items_per_user)\n",
    "\n",
    "    # Compute the number of unique users and items\n",
    "    num_unique_users = sparsified_data['user_id'].nunique()\n",
    "    num_unique_items = sparsified_data['item_id'].nunique()\n",
    "\n",
    "    # Compute sparsity\n",
    "    sparsity = 1 - len(sparsified_data) / (num_unique_users * num_unique_items)\n",
    "    print(f\"Number of unique users: {num_unique_users}\")\n",
    "    print(f\"Number of unique items: {num_unique_items}\")\n",
    "    print(f\"Number of interactions: {len(sparsified_data)}\")\n",
    "    print(f\"Sparsity: {sparsity:.6%}\")\n",
    "\n",
    "    return sparsified_data, sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tomplay():\n",
    "    file_path = f'../results/recommendation/Tomplay/interactions.csv'\n",
    "    data = pd.read_csv(file_path, usecols=[\"USER_ID\", \"ITEM_ID\", \"TIMESTAMP\"])\n",
    "    # Rename the columns to lowercase\n",
    "    data.rename(columns=lambda x: x.lower(), inplace=True)\n",
    "\n",
    "    data['rating'] = 1\n",
    "\n",
    "    # Sort the DataFrame by timestamp in descending order\n",
    "    data = data.sort_values(by='timestamp', ascending=False)\n",
    "\n",
    "    # Remove duplicates, keeping the first occurrence\n",
    "    data = data.drop_duplicates(subset=['user_id', 'item_id'], keep='first')\n",
    "\n",
    "    data, _ = sparsify_data(data, 30)\n",
    "\n",
    "    unique_user_ids = data['user_id'].unique()\n",
    "    print(f\"Number of users: {len(unique_user_ids)}\")\n",
    "    unique_item_ids = data['item_id'].unique()\n",
    "    print(f\"Number of items: {len(unique_item_ids)}\")\n",
    "\n",
    "    train_data, test_data, other_data = train_test_split(data)\n",
    "    print(f\"Tomplay - Proportion of positive ratings affected to test set: {round(len(test_data)/(len(test_data)+len(train_data))*100,2)} %\")\n",
    "\n",
    "    data, train_data, test_data, user_id_mapping, item_id_mapping = map_ids(data, train_data, test_data)\n",
    "\n",
    "    # Compute the number of unique users and items and print\n",
    "    num_unique_users = data['mapped_user_id'].nunique()\n",
    "    num_unique_items = data['mapped_item_id'].nunique()\n",
    "    print(f\"Number of unique users: {num_unique_users}\")\n",
    "    print(f\"Number of unique items: {num_unique_items}\")\n",
    "    # Print the number of interactions\n",
    "    print(f\"Number of interactions: {len(data)}\")\n",
    "    # Compute sparsity\n",
    "    sparsity = 1 - len(data) / (num_unique_users * num_unique_items)\n",
    "    print(f\"Sparsity: {sparsity:.2%}\")\n",
    "\n",
    "    ##### Load embeddings #####\n",
    "\n",
    "    items_embeddings = None\n",
    "    if ada or bert or content_based:\n",
    "        items_embeddings = {}\n",
    "        \n",
    "        embeddings_file = f\"../results/recommendation/embeddings_tomplay.csv.gz\"\n",
    "\n",
    "        embedding_models = {\"ada\": ada, \"bert\": bert}\n",
    "        if content_based:\n",
    "            embedding_models = {\"ada\": True, \"bert\": True}\n",
    "\n",
    "        df = pd.read_csv(embeddings_file)\n",
    "        df = df.rename(columns={'ITEM_ID': 'item_id'})\n",
    "        \n",
    "        # Iterate over the dictionary\n",
    "        for embedding_model, is_enabled in embedding_models.items():\n",
    "            if not is_enabled:\n",
    "                continue\n",
    "            embedding_key = embedding_model + \"_embedding\"\n",
    "            assert data[data['item_id'].isin(df[df[embedding_key].isnull()]['item_id'])].empty # Already removed the article\n",
    "            df2 = df[~ df[embedding_key].isnull()]\n",
    "            df2 = df2.rename(columns={embedding_key: 'embedding'})\n",
    "            df2['embedding'] = df2['embedding'].apply(ast.literal_eval) #Convert list stored as a str to real list type\n",
    "            df2['mapped_item_id'] = df2['item_id'].map(item_id_mapping).astype('Int64')\n",
    "            df2 = df2.dropna(subset=['mapped_item_id']) # If NA, item is not in train set nor test set\n",
    "            items_embeddings[embedding_model] = df2[['item_id', 'mapped_item_id', 'embedding']]\n",
    "\n",
    "    ###########################    \n",
    "\n",
    "\n",
    "    return {\n",
    "            'data': data,\n",
    "            'train_data': train_data,\n",
    "            'test_data': test_data,\n",
    "            'user_id_mapping': user_id_mapping,\n",
    "            'item_id_mapping': item_id_mapping,\n",
    "            'items_embeddings': items_embeddings\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(recommendations, real_items, k):\n",
    "    \"\"\"\n",
    "    Compute NDCG at rank k\n",
    "    \"\"\"\n",
    "    ranked_list = [1 if item_id in real_items else 0 for item_id in recommendations]\n",
    "    num_relevant = min(k, len(real_items))\n",
    "    ideal_list = [1] * num_relevant + [0] * (k - num_relevant)\n",
    "    dcg = sum((2 ** rel - 1) / np.log2(idx + 2) for idx, rel in enumerate(ranked_list[:k]))\n",
    "    idcg = sum((2 ** rel - 1) / np.log2(idx + 2) for idx, rel in enumerate(ideal_list[:k]))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def mrr_at_k(recommendations, real_items, k):\n",
    "    \"\"\"\n",
    "    Compute MRR at rank k\n",
    "    \"\"\"\n",
    "    ranked_list = [1 if item_id in real_items else 0 for item_id in recommendations]\n",
    "    for idx, rel in enumerate(ranked_list[:k]):\n",
    "        if rel > 0:\n",
    "            return 1 / (idx + 1)\n",
    "    return 0\n",
    "\n",
    "def precision_at_k(recommendations, real_items, k):\n",
    "    \"\"\"\n",
    "    Compute Precision at rank k\n",
    "    \"\"\"\n",
    "    return sum([1 if item_id in real_items else 0 for item_id in recommendations[:k]]) / min(k, len(recommendations))\n",
    "\n",
    "def recall_at_k(recommendations, real_items, k):\n",
    "    \"\"\"\n",
    "    Compute Recall at rank k\n",
    "    \"\"\"\n",
    "    return sum([1 if item_id in real_items else 0 for item_id in recommendations[:k]]) / len(real_items)\n",
    "\n",
    "def f1_at_k(precision_at_k, recall_at_k):\n",
    "    \"\"\"\n",
    "    Compute F1 at rank k\n",
    "    \"\"\"\n",
    "    if precision_at_k == 0 and recall_at_k == 0:\n",
    "        return 0\n",
    "\n",
    "    f1_score = 2 * (precision_at_k * recall_at_k) / (precision_at_k + recall_at_k)\n",
    "    return f1_score\n",
    "\n",
    "def average_precision_at_k(recommendations, test_items, k):\n",
    "\n",
    "    recommendations_presence = [1 if item_id in test_items else 0 for item_id in recommendations[:k]]\n",
    "\n",
    "    # Keep track of the number of relevant items found\n",
    "    num_relevant = 0\n",
    "    # Keep track of the sum of precisions\n",
    "    sum_precisions = 0\n",
    "    # We are interested in the precision at each point a relevant document is retrieved\n",
    "    for idx in range(min(k, len(recommendations_presence))):\n",
    "        # Check if the item is relevant\n",
    "        if recommendations_presence[idx] == 1:\n",
    "            # Increment the count of relevant items\n",
    "            num_relevant += 1\n",
    "            # Update the sum of precisions\n",
    "            sum_precisions += num_relevant / (idx + 1)\n",
    "\n",
    "    return sum_precisions / min(k, len(test_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_data, data_full, data_strategy, RS_strategy_name, RS_strategy, model_name, model, dataset, k=5, progress=True):\n",
    "\n",
    "    global user_embedding\n",
    "    global item_embeddings\n",
    "    \n",
    "    ndcgs = []\n",
    "    rrs = []\n",
    "    aps = []  \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    all_recommendations = []\n",
    "    all_really_in_test = []\n",
    "\n",
    "    # Loop for each user in test_df\n",
    "    user_ids = test_data['mapped_user_id'].unique()\n",
    "\n",
    "    if progress:\n",
    "        user_ids_for_loop = tqdm(user_ids, desc=\"Users\")\n",
    "    else:\n",
    "        user_ids_for_loop = user_ids   \n",
    "    for user in user_ids_for_loop:\n",
    "\n",
    "        if RS_strategy_name==\"CF\" and data_strategy==\"implicit\":\n",
    "            top_k_recommendations = model['model'].recommend(user, RS_strategy['user_item_train_data'][user], k)[0]\n",
    "            user_test_items = test_data[test_data['mapped_user_id'] == user].mapped_item_id.tolist()\n",
    "        \n",
    "        elif RS_strategy_name==\"content-based\":\n",
    "\n",
    "            # Get the list of item_ids from train_data that the user has already interacted with.\n",
    "            train_data_items = data_strategy['train_data'][data_strategy['train_data']['mapped_user_id'] == user]['mapped_item_id'].tolist()\n",
    "            # Get the similarity scores and filter out items present in train_data.\n",
    "            filtered_sim_scores = model['sim_matrix'].loc[user].drop(train_data_items)\n",
    "            # Now sort the remaining items and select the top k items.\n",
    "            top_k_recommendations = np.array(filtered_sim_scores.sort_values(ascending=False).index.tolist()[:k])\n",
    "            user_test_items = test_data[test_data['mapped_user_id'] == user].mapped_item_id.tolist()\n",
    "\n",
    "        elif RS_strategy_name==\"graph-based\":\n",
    "\n",
    "            top_k_recommendations = model['model'].recommend_k_items(pd.DataFrame({'userID': [user]}), top_k=k, remove_seen=True)\n",
    "            top_k_recommendations = top_k_recommendations['itemID'].tolist()\n",
    "            user_test_items = test_data[test_data['mapped_user_id'] == user].mapped_item_id.tolist()\n",
    "\n",
    "        ndcg = ndcg_at_k(top_k_recommendations, user_test_items, k)\n",
    "        rr = mrr_at_k(top_k_recommendations, user_test_items, k)\n",
    "        ap = average_precision_at_k(top_k_recommendations, user_test_items, k)\n",
    "        precision = precision_at_k(top_k_recommendations, user_test_items, k)\n",
    "        recall = recall_at_k(top_k_recommendations, user_test_items, k)\n",
    "        f1 = f1_at_k(precision, recall)\n",
    "\n",
    "        ndcgs.append(ndcg)\n",
    "        rrs.append(rr)\n",
    "        aps.append(ap)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    mndcg = np.mean(ndcgs)\n",
    "    mrr = np.mean(rrs)\n",
    "    map = np.mean(aps)\n",
    "    mprecision = np.mean(precisions)\n",
    "    mrecall = np.mean(recalls)\n",
    "    mf1 = np.mean(f1s)\n",
    "\n",
    "    return {\n",
    "        'mndcg': mndcg,\n",
    "        'mrr': mrr,\n",
    "        'map': map,\n",
    "        'mrecall': mrecall,\n",
    "        'mprecision': mprecision,\n",
    "        'mf1': mf1,\n",
    "        'ndcgs': ndcgs,\n",
    "        'rrs': rrs,\n",
    "        'aps': aps,\n",
    "        'recalls': recalls,\n",
    "        'precisions': precisions,\n",
    "        'f1s': f1s,\n",
    "        'all_recommendations': all_recommendations,\n",
    "        'all_really_in_test': all_really_in_test\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tomplay():\n",
    "    file_path = f'../results/recommendation/Tomplay/interactions.csv'\n",
    "    data = pd.read_csv(file_path, usecols=[\"USER_ID\", \"ITEM_ID\", \"TIMESTAMP\"])\n",
    "    # Rename the columns to lowercase\n",
    "    data.rename(columns=lambda x: x.lower(), inplace=True)\n",
    "\n",
    "    data['rating'] = 1\n",
    "\n",
    "    # Sort the DataFrame by timestamp in descending order\n",
    "    data = data.sort_values(by='timestamp', ascending=False)\n",
    "    # Remove duplicates, keeping the first occurrence\n",
    "    data = data.drop_duplicates(subset=['user_id', 'item_id'], keep='first')\n",
    "\n",
    "    data, _ = sparsify_data(data, 30)\n",
    "\n",
    "    unique_user_ids = data['user_id'].unique()\n",
    "    print(f\"Number of users: {len(unique_user_ids)}\")\n",
    "    unique_item_ids = data['item_id'].unique()\n",
    "    print(f\"Number of items: {len(unique_item_ids)}\")\n",
    "\n",
    "    train_data, test_data, other_data, cold_start_test_data = train_test_split(data)\n",
    "    print(f\"Tomplay - Proportion of positive ratings affected to test set: {round(len(test_data)/(len(test_data)+len(train_data))*100,2)} %\")\n",
    "\n",
    "    data, train_data, test_data, user_id_mapping, item_id_mapping = map_ids(data, train_data, test_data)\n",
    "\n",
    "    # Compute the number of unique users and items and print\n",
    "    num_unique_users = data['mapped_user_id'].nunique()\n",
    "    num_unique_items = data['mapped_item_id'].nunique()\n",
    "    print(f\"Number of unique users: {num_unique_users}\")\n",
    "    print(f\"Number of unique items: {num_unique_items}\")\n",
    "    # Print the number of interactions\n",
    "    print(f\"Number of interactions: {len(data)}\")\n",
    "    # Compute sparsity\n",
    "    sparsity = 1 - len(data) / (num_unique_users * num_unique_items)\n",
    "    print(f\"Sparsity: {sparsity:.2%}\")\n",
    "\n",
    "    ##### Load embeddings #####\n",
    "\n",
    "    items_embeddings = None\n",
    "    if ada or bert or content_based:\n",
    "        items_embeddings = {}\n",
    "        \n",
    "        embeddings_file = f\"../results/recommendation/embeddings_tomplay.csv.gz\"\n",
    "        \n",
    "        embedding_models = {\"ada\": ada, \"bert\": bert}\n",
    "        if content_based:\n",
    "            embedding_models = {\"ada\": True, \"bert\": True}\n",
    "\n",
    "        df = pd.read_csv(embeddings_file)\n",
    "        df = df.rename(columns={'ITEM_ID': 'item_id'})\n",
    "        \n",
    "        # Iterate over the dictionary\n",
    "        for embedding_model, is_enabled in embedding_models.items():\n",
    "            if not is_enabled:\n",
    "                continue\n",
    "            embedding_key = embedding_model + \"_embedding\"\n",
    "            assert data[data['item_id'].isin(df[df[embedding_key].isnull()]['item_id'])].empty # Already removed the article\n",
    "            df2 = df[~ df[embedding_key].isnull()]\n",
    "            df2 = df2.rename(columns={embedding_key: 'embedding'})\n",
    "            df2['embedding'] = df2['embedding'].apply(ast.literal_eval) #Convert list stored as a str to real list type\n",
    "            df2['mapped_item_id'] = df2['item_id'].map(item_id_mapping).astype('Int64')\n",
    "            df2 = df2.dropna(subset=['mapped_item_id']) # If NA, item is not in train set nor test set\n",
    "            items_embeddings[embedding_model] = df2[['item_id', 'mapped_item_id', 'embedding']]\n",
    "\n",
    "    ###########################    \n",
    "\n",
    "    return {\n",
    "            'data': data,\n",
    "            'train_data': train_data,\n",
    "            'test_data': test_data,\n",
    "            'user_id_mapping': user_id_mapping,\n",
    "            'item_id_mapping': item_id_mapping,\n",
    "            'items_embeddings': items_embeddings\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "# 1. Zeegu\n",
    "if lingorank:\n",
    "    datasets['LingoRank'] = {}\n",
    "    datasets['LingoRank']['implicit'] = load_LingoRank()\n",
    "    assert set(datasets['LingoRank']['implicit']['data'].dropna(subset=['mapped_user_id'])['mapped_user_id'].astype(int)) == set(range(int(datasets['LingoRank']['implicit']['data']['mapped_user_id'].max()) + 1)), \"User IDs are not continuous and ordered.\"\n",
    "    assert set(datasets['LingoRank']['implicit']['data'].dropna(subset=['mapped_item_id'])['mapped_item_id'].astype(int)) == set(range(int(datasets['LingoRank']['implicit']['data']['mapped_item_id'].max()) + 1)), \"Item IDs are not continuous and ordered.\"\n",
    "\n",
    "# 2. MovieLens-100k\n",
    "if ml_100k:\n",
    "    datasets['ml-100k'] = {}\n",
    "    datasets['ml-100k']['implicit'] = load_ml_100k()\n",
    "    assert set(datasets['ml-100k']['implicit']['data'].dropna(subset=['mapped_user_id'])['mapped_user_id'].astype(int)) == set(range(int(datasets['ml-100k']['implicit']['data']['mapped_user_id'].max()) + 1)), \"User IDs are not continuous and ordered.\"\n",
    "    assert set(datasets['ml-100k']['implicit']['data'].dropna(subset=['mapped_item_id'])['mapped_item_id'].astype(int)) == set(range(int(datasets['ml-100k']['implicit']['data']['mapped_item_id'].max()) + 1)), \"Item IDs are not continuous and ordered.\"\n",
    "\n",
    "# 3. Goodreads\n",
    "if goodreads:\n",
    "    datasets['Goodreads'] = {}\n",
    "    datasets['Goodreads']['implicit'] = load_goodreads()\n",
    "    assert set(datasets['Goodreads']['implicit']['data'].dropna(subset=['mapped_user_id'])['mapped_user_id'].astype(int)) == set(range(int(datasets['Goodreads']['implicit']['data']['mapped_user_id'].max()) + 1)), \"User IDs are not continuous and ordered.\"\n",
    "    assert set(datasets['Goodreads']['implicit']['data'].dropna(subset=['mapped_item_id'])['mapped_item_id'].astype(int)) == set(range(int(datasets['Goodreads']['implicit']['data']['mapped_item_id'].max()) + 1)), \"Item IDs are not continuous and ordered.\"\n",
    "\n",
    "# 4. Tomplay\n",
    "if tomplay:\n",
    "    datasets['Tomplay'] = {}\n",
    "    datasets['Tomplay']['implicit'] = {}\n",
    "    datasets['Tomplay']['implicit'] = load_tomplay()\n",
    "    assert set(datasets['Tomplay']['implicit']['data'].dropna(subset=['mapped_user_id'])['mapped_user_id'].astype(int)) == set(range(int(datasets['Tomplay']['implicit']['data']['mapped_user_id'].max()) + 1)), \"User IDs are not continuous and ordered.\"\n",
    "    assert set(datasets['Tomplay']['implicit']['data'].dropna(subset=['mapped_item_id'])['mapped_item_id'].astype(int)) == set(range(int(datasets['Tomplay']['implicit']['data']['mapped_item_id'].max()) + 1)), \"Item IDs are not continuous and ordered.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the structure of our dict\n",
    "def display_keys(d, indent=0):\n",
    "    for key, value in d.items():\n",
    "        print('  ' * indent + str(key))\n",
    "        if isinstance(value, dict) and key != \"user_id_mapping\" and key != \"item_id_mapping\":\n",
    "            display_keys(value, indent+1)\n",
    "\n",
    "display_keys(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key_dataset, dataset in tqdm(datasets.items()):\n",
    "    dataset['implicit']['RS_strategy'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cf:\n",
    "    # Create user-item sparse matrix\n",
    "    for key_dataset, dataset in tqdm(datasets.items()):\n",
    "        dataset['implicit']['RS_strategy']['CF'] = {}\n",
    "        cf = dataset['implicit']['RS_strategy']['CF']\n",
    "        train_data = dataset['implicit']['train_data']\n",
    "\n",
    "        cf['user_item_train_data'] = sparse.csr_matrix(\n",
    "            (train_data['rating'].astype(float), (train_data['mapped_user_id'], train_data['mapped_item_id']))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User embeddings\n",
    "def compute_user_embeddings(train_data, embeddings_df, n):\n",
    "    # Group train_data by user_id and sort by timestamp\n",
    "    train_data_sorted = train_data.sort_values(by=['mapped_user_id', 'timestamp'], ascending=[True, False])\n",
    "    train_data_grouped = train_data_sorted.groupby('mapped_user_id')\n",
    "\n",
    "    # Initialize empty DataFrame to store user embeddings\n",
    "    user_embeddings = pd.DataFrame(columns=['mapped_user_id', 'embedding', 'num_items'])\n",
    "\n",
    "    real_nb_neigh = []\n",
    "    # Iterate through each user in train_data\n",
    "    for user_id, user_data in tqdm(train_data_grouped, desc=\"Compute user embeddings\"):\n",
    "        # Get the last n articles the user interacted with\n",
    "        item_ids = user_data['mapped_item_id'].head(n).tolist()\n",
    "        real_nb_neigh.append(len(item_ids))\n",
    "\n",
    "        # Get the embeddings for these articles\n",
    "        item_embeddings = np.stack(embeddings_df[embeddings_df['mapped_item_id'].isin(item_ids)]['embedding'])\n",
    "\n",
    "        # Compute the mean embedding for the user\n",
    "        user_embedding = np.mean(item_embeddings, axis=0)\n",
    "\n",
    "        # Add the user embedding to the DataFrame\n",
    "        num_items = len(item_embeddings)\n",
    "        user_embeddings.loc[len(user_embeddings)] = [user_id, user_embedding, num_items]\n",
    "\n",
    "    real_nb_neigh = sum(real_nb_neigh)/len(real_nb_neigh)\n",
    "\n",
    "    return user_embeddings, real_nb_neigh\n",
    "\n",
    "def compute_similarity_matrix(items_embeddings, users_embeddings, user=None):\n",
    "\n",
    "    if user is not None:\n",
    "        users_embeddings = users_embeddings[users_embeddings['mapped_user_id'] == user]\n",
    "\n",
    "    # Convert the embeddings to numpy arrays\n",
    "    item_embeddings_array = np.vstack(items_embeddings['embedding'].apply(np.array))\n",
    "    user_embeddings_array = np.vstack(users_embeddings['embedding'].apply(np.array))\n",
    "\n",
    "    # Compute the cosine similarity matrix\n",
    "    cosine_sim_matrix = cosine_similarity(user_embeddings_array, item_embeddings_array)\n",
    "\n",
    "    # Convert the cosine similarity matrix into a DataFrame\n",
    "    # Use user_ids for the index and item_ids for the columns\n",
    "    cosine_sim_df = pd.DataFrame(cosine_sim_matrix,\n",
    "                                index=users_embeddings['mapped_user_id'],\n",
    "                                columns=items_embeddings['mapped_item_id'])\n",
    "    \n",
    "    return cosine_sim_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_init(self, hparams, data, initial_embeddings=None ,seed=None):\n",
    "    \n",
    "    \"\"\"Initializing the model. Create parameters, placeholders, embeddings and loss function.\n",
    "\n",
    "    Args:\n",
    "        hparams (HParams): A HParams object, hold the entire set of hyperparameters.\n",
    "        data (object): A recommenders.models.deeprec.DataModel.ImplicitCF object, load and process data.\n",
    "        seed (int): Seed.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    self.data = data\n",
    "    self.epochs = hparams.epochs\n",
    "    self.lr = hparams.learning_rate\n",
    "    self.emb_dim = hparams.embed_size\n",
    "    self.batch_size = hparams.batch_size\n",
    "    self.n_layers = hparams.n_layers\n",
    "    self.decay = hparams.decay\n",
    "    self.eval_epoch = hparams.eval_epoch\n",
    "    self.top_k = hparams.top_k\n",
    "    self.save_model = hparams.save_model\n",
    "    self.save_epoch = hparams.save_epoch\n",
    "    self.metrics = hparams.metrics\n",
    "    self.model_dir = hparams.MODEL_DIR\n",
    "    self.initial_embeddings = initial_embeddings\n",
    "\n",
    "    metric_options = [\"map\", \"ndcg\", \"precision\", \"recall\"]\n",
    "    for metric in self.metrics:\n",
    "        if metric not in metric_options:\n",
    "            raise ValueError(\n",
    "                \"Wrong metric(s), please select one of this list: {}\".format(\n",
    "                    metric_options\n",
    "                )\n",
    "            )\n",
    "\n",
    "    self.norm_adj = data.get_norm_adj_mat()\n",
    "\n",
    "    self.n_users = data.n_users\n",
    "    self.n_items = data.n_items\n",
    "\n",
    "    self.users = tf.compat.v1.placeholder(tf.int32, shape=(None,))\n",
    "    self.pos_items = tf.compat.v1.placeholder(tf.int32, shape=(None,))\n",
    "    self.neg_items = tf.compat.v1.placeholder(tf.int32, shape=(None,))\n",
    "\n",
    "    self.weights = self._init_weights()\n",
    "    self.ua_embeddings, self.ia_embeddings = self._create_lightgcn_embed()\n",
    "\n",
    "    self.u_g_embeddings = tf.nn.embedding_lookup(\n",
    "        params=self.ua_embeddings, ids=self.users\n",
    "    )\n",
    "    self.pos_i_g_embeddings = tf.nn.embedding_lookup(\n",
    "        params=self.ia_embeddings, ids=self.pos_items\n",
    "    )\n",
    "    self.neg_i_g_embeddings = tf.nn.embedding_lookup(\n",
    "        params=self.ia_embeddings, ids=self.neg_items\n",
    "    )\n",
    "    self.u_g_embeddings_pre = tf.nn.embedding_lookup(\n",
    "        params=self.weights[\"user_embedding\"], ids=self.users\n",
    "    )\n",
    "    self.pos_i_g_embeddings_pre = tf.nn.embedding_lookup(\n",
    "        params=self.weights[\"item_embedding\"], ids=self.pos_items\n",
    "    )\n",
    "    self.neg_i_g_embeddings_pre = tf.nn.embedding_lookup(\n",
    "        params=self.weights[\"item_embedding\"], ids=self.neg_items\n",
    "    )\n",
    "\n",
    "    self.batch_ratings = tf.matmul(\n",
    "        self.u_g_embeddings,\n",
    "        self.pos_i_g_embeddings,\n",
    "        transpose_a=False,\n",
    "        transpose_b=True,\n",
    "    )\n",
    "\n",
    "    self.mf_loss, self.emb_loss = self._create_bpr_loss(\n",
    "        self.u_g_embeddings, self.pos_i_g_embeddings, self.neg_i_g_embeddings\n",
    "    )\n",
    "    self.loss = self.mf_loss + self.emb_loss\n",
    "\n",
    "    self.opt = tf.compat.v1.train.AdamOptimizer(learning_rate=self.lr).minimize(\n",
    "        self.loss\n",
    "    )\n",
    "    self.saver = tf.compat.v1.train.Saver(max_to_keep=1)\n",
    "\n",
    "    gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
    "    self.sess = tf.compat.v1.Session(\n",
    "        config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)\n",
    "    )\n",
    "    self.sess.run(tf.compat.v1.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_init_weights(self):\n",
    "    \"\"\"Initialize user and item embeddings.\n",
    "\n",
    "    Returns:\n",
    "        dict: With keys `user_embedding` and `item_embedding`, embeddings of all users and items.\n",
    "\n",
    "    \"\"\"\n",
    "    all_weights = dict()\n",
    "    initializer = tf.compat.v1.keras.initializers.VarianceScaling(\n",
    "        scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"\n",
    "    )\n",
    "\n",
    "    if self.initial_embeddings is not None:\n",
    "        all_weights[\"item_embedding\"] = tf.Variable(self.initial_embeddings['item_embedding'], dtype=tf.float32, name=\"item_embedding\")\n",
    "        all_weights[\"user_embedding\"] = tf.Variable(self.initial_embeddings['user_embedding'], dtype=tf.float32, name=\"user_embedding\")\n",
    "        print(\"Using pretrained embeddings.\")\n",
    "    else:\n",
    "        all_weights[\"user_embedding\"] = tf.Variable(\n",
    "            initializer([self.n_users, self.emb_dim]), name=\"user_embedding\"\n",
    "        )\n",
    "        all_weights[\"item_embedding\"] = tf.Variable(\n",
    "            initializer([self.n_items, self.emb_dim]), name=\"item_embedding\"\n",
    "        )\n",
    "        print(\"Using xavier initialization.\")\n",
    "\n",
    "    return all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LightGCN.__init__ = new_init\n",
    "LightGCN._init_weights = new_init_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lightgcn:\n",
    "    for key_dataset, dataset in tqdm(datasets.items()):\n",
    "        dataset['implicit']['RS_strategy']['graph-based'] = {}\n",
    "        graph_based = dataset['implicit']['RS_strategy']['graph-based']\n",
    "        dataset['implicit']['RS_strategy']['graph-based']['models'] = {}\n",
    "        dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN'] = {}\n",
    "\n",
    "        dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['embedding_model'] = {}\n",
    "\n",
    "        print(\"=\"*100)\n",
    "        print(key_dataset)\n",
    "        print(\"=\"*100)\n",
    "\n",
    "        embeddings_models = [\"ada\" if (ada or xavier_ada) else None] + [\"bert\" if (bert or xavier_bert) else None]\n",
    "        embedding_models = [embeddings_model for embeddings_model in embeddings_models if embeddings_model is not None]\n",
    "        # for embedding_model in dataset['implicit']['items_embeddings'].keys():\n",
    "        for embedding_model in embedding_models:\n",
    "            dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['embedding_model'][embedding_model] = {}\n",
    "            dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['embedding_model'][embedding_model]['method'] = {}\n",
    "            # if embedding_model==\"bert\": continue\n",
    "            print(\"-\"*100)\n",
    "            print(embedding_model)\n",
    "            print(\"-\"*100)\n",
    "                \n",
    "            for method in [method for method in ['Xavier' if xavier_ada or xavier_bert else None] + ['precomputed' if ada or bert else None] if method is not None]:\n",
    "                print(\"*\"*50)\n",
    "                print(method)\n",
    "                print(\"*\"*50)\n",
    "\n",
    "                dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['embedding_model'][embedding_model]['method'][method] = {}\n",
    "\n",
    "                train_data = dataset['implicit']['train_data'].copy()\n",
    "                train_data = train_data.rename(columns = {'mapped_user_id':'userID', 'mapped_item_id':'itemID'})\n",
    "            \n",
    "                test_data = dataset['implicit']['test_data'].copy()\n",
    "                test_data = test_data.rename(columns = {'mapped_user_id':'userID', 'mapped_item_id':'itemID'})\n",
    "                    \n",
    "                dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['data'] = ImplicitCF(train=train_data, test=test_data, seed=my_seed, col_user='userID', col_item='itemID', col_rating='rating')\n",
    "                data = dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['data']\n",
    "\n",
    "                try:\n",
    "                    embed_size = len(dataset['implicit']['items_embeddings'][embedding_model]['embedding'].iloc[0])\n",
    "                except:\n",
    "                    if embedding_model==\"ada\":\n",
    "                        embed_size = 1536\n",
    "                    elif embedding_model==\"bert\":\n",
    "                        embed_size = 768\n",
    "                assert (xavier_ada or ada) and embed_size==1536 or (xavier_bert or bert) and embed_size==768, \"Embedding size is not correct\"\n",
    "                print(f\"Embedding size: {embed_size}\")\n",
    "\n",
    "                if method==\"precomputed\":\n",
    "                    item_embeddings = dataset['implicit']['items_embeddings'][embedding_model]\n",
    "\n",
    "                    item_embeddings = item_embeddings[item_embeddings.mapped_item_id.isin(set(train_data.itemID).union(set(test_data.itemID)))]\n",
    "                    item_embeddings = item_embeddings.sort_values(by='mapped_item_id', ascending=True)\n",
    "                    assert item_embeddings[item_embeddings.mapped_item_id.isin(set(train_data.itemID).union(set(test_data.itemID)))].mapped_item_id.is_monotonic_increasing, 'not ordered by item_id'\n",
    "\n",
    "                    initial_embeddings = {}\n",
    "                    initial_embeddings['item_embedding'] = np.vstack(item_embeddings[item_embeddings.mapped_item_id.isin(set(train_data.itemID).union(test_data.itemID))].embedding.values)\n",
    "                    ns = lightgcn_params['n']\n",
    "                elif method==\"Xavier\":\n",
    "                    initial_embeddings = None\n",
    "                    ns = [None]\n",
    "\n",
    "                all_hparams_best_model = None\n",
    "                all_hparams_best_ndcg = 0\n",
    "                best_hparams = None\n",
    "                best_hparams_for_init = None\n",
    "                best_initial_embeddings = None\n",
    "\n",
    "                if save_tqdm_to_file:\n",
    "                    f = open(tqdm_file, \"w\")\n",
    "                else:\n",
    "                    f = None\n",
    "                total_configs = len(lightgcn_params['n_layers'])*len(ns)*len(lightgcn_params['lr'])\n",
    "                config = 0\n",
    "\n",
    "                for n_layers, n, lr in tqdm(itertools.product(lightgcn_params['n_layers'], ns , lightgcn_params['lr']), total=total_configs, file=f):\n",
    "                    \n",
    "                    print(\"^\"*50)    \n",
    "                    print(f\"n_layers: {n_layers} - n: {n} - lr: {lr}\")\n",
    "                    print(\"^\"*50) \n",
    "                    if method==\"precomputed\":\n",
    "                        user_embeddings, real_nb_neigh = compute_user_embeddings(dataset['implicit']['train_data'], item_embeddings, n)\n",
    "                        initial_embeddings['user_embedding'] = np.vstack(user_embeddings[user_embeddings.mapped_user_id.isin(set(train_data.userID))].embedding.values)\n",
    "                \n",
    "\n",
    "                    hparams = prepare_hparams(                          \n",
    "                                learning_rate=lr,\n",
    "                                eval_epoch=10000000,\n",
    "                                top_k=5,\n",
    "                                save_model=False,\n",
    "                                epochs=1,\n",
    "                                save_epoch=1,\n",
    "                                model_type=\"lightgcn\",\n",
    "                                embed_size=embed_size,\n",
    "                                n_layers=n_layers,\n",
    "                                batch_size=1024,\n",
    "                                decay=0.0001,\n",
    "                                metrics=[\"recall\", \"ndcg\", \"precision\", \"map\"],\n",
    "                                MODEL_DIR=\"./tests/resources/deeprec/lightgcn/model/lightgcn_model/\"\n",
    "                                )\n",
    "                \n",
    "                \n",
    "                    best_model = None\n",
    "                    best_ndcg = 0\n",
    "                    tf.compat.v1.set_random_seed(my_seed)\n",
    "                    tf.random.set_seed(my_seed)\n",
    "                    np.random.seed(my_seed)\n",
    "                    random.seed(my_seed)\n",
    "                    model = LightGCN(hparams, data, initial_embeddings=initial_embeddings, seed=my_seed)\n",
    "                    save_path = f\"../results/lightgcn_model_{embedding_model}_{method}/best_model\"\n",
    "                    patience_max = 10\n",
    "\n",
    "                    with Timer() as train_time:\n",
    "                        for epoch in range(sys.maxsize):\n",
    "                            model.fit()\n",
    "                            eval_start = time.time()\n",
    "                            recall, ndcg, precision, map = model.run_eval()\n",
    "                            eval_end = time.time()\n",
    "                            eval_time = eval_end - eval_start         \n",
    "                            print(f\"Evaluation time: {eval_time:.1f}s\")\n",
    "                            print(f\"Epoch {epoch} - Recall@5: {recall:.4f} - NDCG@5: {ndcg:.4f} - Precision@5: {precision:.4f} - MAP@5: {map:.4f}\")\n",
    "                            print(\"------------------------\")\n",
    "                            if ndcg > all_hparams_best_ndcg:\n",
    "                                all_hparams_best_ndcg = ndcg\n",
    "                                best_hparams = {'n_layers': n_layers, 'n': n, 'lr': lr}\n",
    "                                best_hparams_for_init = hparams\n",
    "                                best_initial_embeddings = initial_embeddings\n",
    "                                model.saver.save(model.sess, save_path)\n",
    "                            if ndcg > best_ndcg:\n",
    "                                patience = 0\n",
    "                                best_ndcg = ndcg\n",
    "                                best_epoch = epoch\n",
    "                            else:\n",
    "                                patience += 1\n",
    "                            \n",
    "                            if patience == patience_max:\n",
    "                                print(\"=\"*25 + f\"Best NDCG: {best_ndcg:.4f} at epoch {best_epoch}\" + \"=\"*25)\n",
    "                                break\n",
    "                    print(\"Took {} seconds for training.\".format(train_time.interval))\n",
    "                    \n",
    "                    model.sess.close()  # Close the existing session\n",
    "                    tf.compat.v1.Session().close()\n",
    "                    # Reset the default graph\n",
    "                    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "\n",
    "                model = LightGCN(best_hparams_for_init, data, initial_embeddings=best_initial_embeddings, seed=my_seed)\n",
    "                model.load(save_path)\n",
    "                dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['embedding_model'][embedding_model]['method'][method]['model'] = model\n",
    "                # model.sess.close()  # Close the existing session\n",
    "                tf.compat.v1.Session().close()\n",
    "                # Reset the default graph\n",
    "                tf.compat.v1.reset_default_graph()\n",
    "                model = None\n",
    "    if f is not None:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if content_based:\n",
    "    for key_dataset, dataset in tqdm(datasets.items()):\n",
    "        dataset['implicit']['RS_strategy']['content-based'] = {}\n",
    "        dataset['implicit']['RS_strategy']['content-based']['models'] = {}\n",
    "        for embedding_model in ['ada', 'bert']:\n",
    "            dataset['implicit']['RS_strategy']['content-based']['models'][embedding_model] = {}\n",
    "            # dataset['implicit']['RS_strategy']['content-based']['models'][embedding_model]['k'] = {1: {}}\n",
    "            dataset['implicit']['RS_strategy']['content-based']['models'][embedding_model]['k'] = {1: {}, 2: {}, 3: {}, 4:{}, 5:{}, 10:{}, 20:{}, 30: {}, 50: {}, 100: {}}\n",
    "        # datasets['LingoRank']['implicit']['RS_strategy']['content-based']['models']['ada_v2']['k'] = {10:{}, 100: {}}\n",
    "\n",
    "            train_data = dataset['implicit']['train_data']\n",
    "            \n",
    "            cb_embed = dataset['implicit']['RS_strategy']['content-based']['models'][embedding_model]\n",
    "            for key in cb_embed['k']:\n",
    "                # print(key)\n",
    "                cb_embed['k'][key]['users_embeddings'], cb_embed['k'][key]['mean_k'] = compute_user_embeddings(train_data, dataset['implicit']['items_embeddings'][embedding_model], key)\n",
    "                # Link item embeddings to model so we can access them later\n",
    "                # dataset['implicit']['RS_strategy']['content-based']['models'][embedding_model]['k'][key]['items_embeddings'] = dataset['implicit']['items_embeddings'][embedding_model]\n",
    "                # dataset['implicit']['RS_strategy']['content-based']['models'][embedding_model]['k'][key]['sim_matrix'] = compute_similarity_matrix(dataset['implicit']['items_embeddings'][embedding_model], cb_embed['k'][key]['users_embeddings'])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cf:\n",
    "\n",
    "    if save_tqdm_to_file:\n",
    "        f = open(tqdm_file, \"w\")\n",
    "    else:\n",
    "        f = None\n",
    "    # Create user-item sparse matrix\n",
    "    for key_dataset, dataset in tqdm(datasets.items(), desc=\"Datasets\"):\n",
    "        cf = dataset['implicit']['RS_strategy']['CF']\n",
    "        cf['models'] = {}\n",
    "        if als:\n",
    "            cf['models']['ALS'] = {}\n",
    "            cf['models']['ALS']['config'] = {}\n",
    "            \n",
    "            all_hparams_best_model = None\n",
    "            all_hparams_best_ndcg = 0\n",
    "            best_hparams = None\n",
    "              \n",
    "            for factors, regularization, alpha in tqdm(itertools.product(als_params['factors'], als_params['regularization'], als_params['alpha']), total=len(list(itertools.product(*als_params.values()))), file=f):\n",
    "                \n",
    "                model = implicit.als.AlternatingLeastSquares(factors=factors, regularization=regularization, alpha=alpha, iterations=1, calculate_training_loss=True, random_state=my_seed, use_gpu=False)\n",
    "                training_data = cf['user_item_train_data'].astype('double')\n",
    "                test_data = dataset['implicit']['test_data']\n",
    "                best_ndcg = 0\n",
    "                patience = 0\n",
    "                patience_max = 10\n",
    "                for epoch in range(sys.maxsize):\n",
    "                    model.fit(training_data, show_progress=False)\n",
    "                    # Evaluate the model\n",
    "                    results = evaluate(test_data, None, 'implicit', 'CF', dataset['implicit']['RS_strategy']['CF'], 'ALS', {'model':model}, dataset, k=5, progress=False)\n",
    "                    ndcg = results['mndcg']\n",
    "\n",
    "                    if ndcg > all_hparams_best_ndcg:\n",
    "                        all_hparams_best_ndcg = ndcg\n",
    "                        best_hparams = {'factors': factors, 'regularization': regularization, 'alpha': alpha}\n",
    "                        all_hparams_best_model = copy.deepcopy(model)\n",
    "                    if ndcg > best_ndcg:\n",
    "                        patience = 0\n",
    "                        best_ndcg = ndcg\n",
    "                        best_epoch = epoch\n",
    "                    else:\n",
    "                        patience += 1\n",
    "                    \n",
    "                    if patience == patience_max:\n",
    "                        print(\"-\"*25 + f\"hparams: {{'factors': {factors}, 'regularization': {regularization}, 'alpha': {alpha}}}\" + \"-\"*25)\n",
    "                        print(\"=\"*25 + f\"Best NDCG: {best_ndcg:.4f} at epoch {best_epoch}\" + \"=\"*25)\n",
    "                        break\n",
    "                \n",
    "            cf['models']['ALS']['model'] = all_hparams_best_model\n",
    "            cf['models']['ALS']['config'] = best_hparams\n",
    "\n",
    "            #cf['models']['ALS'] = {'model': implicit.als.AlternatingLeastSquares(factors=50, random_state=my_seed)}\n",
    "        if bpr:\n",
    "            cf['models']['BPR'] = {}\n",
    "            cf['models']['BPR']['config'] = {}\n",
    "            \n",
    "            all_hparams_best_model = None\n",
    "            all_hparams_best_ndcg = 0\n",
    "            best_hparams = None\n",
    "\n",
    "            for factors, regularization, learning_rate, verify_negative_samples in tqdm(itertools.product(bpr_params['factors'], bpr_params['regularization'], bpr_params['learning_rate'], bpr_params['verify_negative_samples']), total=len(list(itertools.product(*bpr_params.values()))), file=f):\n",
    "                \n",
    "                model = implicit.bpr.BayesianPersonalizedRanking(factors=factors, learning_rate=learning_rate, regularization=regularization, verify_negative_samples=verify_negative_samples, iterations=1, random_state=my_seed, use_gpu=False)\n",
    "                training_data = cf['user_item_train_data'].astype('double')\n",
    "                test_data = dataset['implicit']['test_data']\n",
    "                best_ndcg = 0\n",
    "                patience = 0\n",
    "                patience_max = 10\n",
    "                for epoch in range(sys.maxsize):\n",
    "                    model.fit(training_data, show_progress=False)\n",
    "                    # Evaluate the model\n",
    "                    results = evaluate(test_data, None, 'implicit', 'CF', dataset['implicit']['RS_strategy']['CF'], 'BPR', {'model':model}, dataset, k=5, progress=False)\n",
    "                    ndcg = results['mndcg']\n",
    "\n",
    "                    if ndcg > all_hparams_best_ndcg:\n",
    "                        all_hparams_best_ndcg = ndcg\n",
    "                        best_hparams = {'factors': factors, 'regularization': regularization, 'learning_rate': learning_rate, 'verify_negative_samples': verify_negative_samples}\n",
    "                        all_hparams_best_model = copy.deepcopy(model)\n",
    "                    if ndcg > best_ndcg:\n",
    "                        patience = 0\n",
    "                        best_ndcg = ndcg\n",
    "                        best_epoch = epoch\n",
    "                    else:\n",
    "                        patience += 1\n",
    "                    \n",
    "                    if patience == patience_max:\n",
    "                        print(\"-\"*25 + f\"hparams: {{'factors': {factors}, 'regularization': {regularization}, 'learning_rate': {learning_rate}, 'verify_negative_samples': {verify_negative_samples}}}\" + \"-\"*25)\n",
    "                        print(\"=\"*25 + f\"Best NDCG: {best_ndcg:.4f} at epoch {best_epoch}\" + \"=\"*25)\n",
    "                        break\n",
    "                \n",
    "            cf['models']['BPR']['model'] = all_hparams_best_model\n",
    "            cf['models']['BPR']['config'] = best_hparams\n",
    "        if lmf:\n",
    "            \n",
    "            cf['models']['LMF'] = {}\n",
    "            cf['models']['LMF']['config'] = {}\n",
    "            \n",
    "            all_hparams_best_model = None\n",
    "            all_hparams_best_ndcg = 0\n",
    "            best_hparams = None\n",
    "\n",
    "            for factors, regularization, learning_rate, neg_prop in tqdm(itertools.product(lmf_params['factors'], lmf_params['regularization'], lmf_params['learning_rate'], lmf_params['neg_prop']), total=len(list(itertools.product(*lmf_params.values()))), file=f):\n",
    "                \n",
    "                model = implicit.lmf.LogisticMatrixFactorization(factors=factors, learning_rate=learning_rate, regularization=regularization, neg_prop=neg_prop, iterations=1, random_state=my_seed, use_gpu=False)\n",
    "                training_data = cf['user_item_train_data'].astype('double')\n",
    "                test_data = dataset['implicit']['test_data']\n",
    "                best_ndcg = 0\n",
    "                patience = 0\n",
    "                patience_max = 10\n",
    "                for epoch in range(sys.maxsize):\n",
    "                    model.fit(training_data, show_progress=False)\n",
    "                    # Evaluate the model\n",
    "                    results = evaluate(test_data, None, 'implicit', 'CF', dataset['implicit']['RS_strategy']['CF'], 'LMF', {'model':model}, dataset, k=5, progress=False)\n",
    "                    ndcg = results['mndcg']\n",
    "\n",
    "                    if ndcg > all_hparams_best_ndcg:\n",
    "                        all_hparams_best_ndcg = ndcg\n",
    "                        best_hparams = {'factors': factors, 'regularization': regularization, 'learning_rate': learning_rate, 'neg_prop': neg_prop}\n",
    "                        all_hparams_best_model = copy.deepcopy(model)\n",
    "                    if ndcg > best_ndcg:\n",
    "                        patience = 0\n",
    "                        best_ndcg = ndcg\n",
    "                        best_epoch = epoch\n",
    "                    else:\n",
    "                        patience += 1\n",
    "                    \n",
    "                    if patience == patience_max:\n",
    "                        print(\"-\"*25 + f\"hparams: {{'factors': {factors}, 'regularization': {regularization}, 'learning_rate': {learning_rate}, 'neg_prop': {neg_prop}}}\" + \"-\"*25)\n",
    "                        print(\"=\"*25 + f\"Best NDCG: {best_ndcg:.4f} at epoch {best_epoch}\" + \"=\"*25)\n",
    "                        break\n",
    "                \n",
    "            cf['models']['LMF']['model'] = all_hparams_best_model\n",
    "            cf['models']['LMF']['config'] = best_hparams\n",
    "\n",
    "    if save_tqdm_to_file:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_keys(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary !!\n",
    "# datasets['ml-100k'].pop('explicit', None)\n",
    "# datasets.pop('LingoRank', None)\n",
    "# datasets['ml-100k']['implicit']['RS_strategy'].pop('content-based', None)\n",
    "# datasets['ml-100k']['implicit']['RS_strategy'].pop('CF', None)\n",
    "# datasets['LingoRank']['implicit']['RS_strategy'].pop('content-based', None)\n",
    "# datasets['LingoRank']['implicit']['RS_strategy'].pop('CF', None)\n",
    "\n",
    "\n",
    "for key_dataset, dataset in datasets.items():\n",
    "    print(key_dataset)\n",
    "    for key_data_strategy, data_strategy in dataset.items():\n",
    "        print('\\t' + key_data_strategy) \n",
    "        for key_RS_strategy, RS_strategy in data_strategy['RS_strategy'].items():\n",
    "            print('\\t\\t' + key_RS_strategy)\n",
    "            for key_model, model in RS_strategy['models'].items():\n",
    "                print('\\t\\t\\t' + key_model)\n",
    "                # if model.get('method', None):\n",
    "                if model.get('embedding_model', None):\n",
    "                    for key_embedding_model, embedding_model in model['embedding_model'].items():\n",
    "                        for method in embedding_model['method'].keys():\n",
    "                            print('\\t\\t\\t\\t' + key_embedding_model)\n",
    "                            model['embedding_model'][key_embedding_model]['method'][method]['metrics'] = evaluate(data_strategy['test_data'], data_strategy.get('data_full', None), key_data_strategy, key_RS_strategy, RS_strategy, key_model, model['embedding_model'][key_embedding_model]['method'][method], key_dataset, k=5)\n",
    "                elif model.get('k', None):\n",
    "                    for nb_neigh in model['k'].keys():\n",
    "                        model['k'][nb_neigh]['metrics'] = {}\n",
    "                        model['k'][nb_neigh]['sim_matrix'] = compute_similarity_matrix(dataset['implicit']['items_embeddings'][key_model], model['k'][nb_neigh]['users_embeddings'])\n",
    "                        model['k'][nb_neigh]['metrics'] = evaluate(data_strategy['test_data'], data_strategy.get('data_full', None), data_strategy, key_RS_strategy, RS_strategy, key_model, model['k'][nb_neigh], key_dataset, k=5)\n",
    "                        del  model['k'][nb_neigh]['sim_matrix']\n",
    "\n",
    "                else:\n",
    "                    model['metrics'] = {}\n",
    "                    model['metrics'] = evaluate(data_strategy['test_data'], data_strategy.get('data_full', None), key_data_strategy, key_RS_strategy, RS_strategy, key_model, model, key_dataset, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_keys(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best hparams to a CSV file\n",
    "if 'best_hparams' in globals() or 'best_hparams' in locals():\n",
    "    best_hparams_df = pd.DataFrame(list(best_hparams.items()), columns=['Parameter', 'Value'])\n",
    "    best_hparams_df.to_csv(best_hparams_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "k=5\n",
    "# Extracting evaluation results\n",
    "data = []\n",
    "\n",
    "for key_dataset, dataset in datasets.items():\n",
    "    print(key_dataset)\n",
    "    for key_data_strategy, data_strategy in dataset.items():\n",
    "        # print('\\t' + key_data_strategy) \n",
    "        for key_RS_strategy, RS_strategy in data_strategy['RS_strategy'].items():\n",
    "            # print('\\t\\t' + key_RS_strategy)\n",
    "            for key_model, model in RS_strategy['models'].items():\n",
    "                # print('\\t\\t\\t' + key_model)\n",
    "                \n",
    "                if model.get('k', None):\n",
    "                    for nb_neigh in model['k'].keys():\n",
    "                        metrics = model['k'][nb_neigh]['metrics']\n",
    "                        row = {\n",
    "                            'dataset': key_dataset,\n",
    "                            'data_strategy': key_data_strategy, \n",
    "                            'RS_strategy': key_RS_strategy,\n",
    "                            'model': key_model,\n",
    "                            'embeddind_model': key_model,\n",
    "                            'nb_neighbours_asked': int(nb_neigh),\n",
    "                            'nb_neighbours_mean': model['k'][nb_neigh]['mean_k'],\n",
    "                            f'Recall@{k}': f\"{metrics.get('mrecall'):.4f}\",\n",
    "                            f'Precision@{k}': f\"{metrics.get('mprecision'):.4f}\",\n",
    "                            f'F1@{k}': f\"{metrics.get('mf1'):.4f}\" ,\n",
    "                            f'NDCG@{k}': f\"{metrics.get('mndcg'):.4f}\",  \n",
    "                            f'MRR@{k}': f\"{metrics.get('mrr'):.4f}\",\n",
    "                            f'MAP@{k}': f\"{metrics.get('map'):.4f}\"\n",
    "                                 \n",
    "                        }\n",
    "                        data.append(row)\n",
    "                # elif model.get('method', None):\n",
    "                elif model.get('embedding_model', None):\n",
    "                    for key_embedding_model, embedding_model in model['embedding_model'].items():\n",
    "                        for method in embedding_model['method'].keys():\n",
    "                            metrics = model['embedding_model'][key_embedding_model]['method'][method]['metrics']\n",
    "                            row = {\n",
    "                                'dataset': key_dataset,\n",
    "                                'data_strategy': key_data_strategy, \n",
    "                                'RS_strategy': key_RS_strategy,\n",
    "                                'model': key_model,\n",
    "                                'embeddind_model': key_embedding_model,\n",
    "                                'nb_neighbours_asked': None,\n",
    "                                'nb_neighbours_mean': method,\n",
    "                                f'Recall@{k}': f\"{metrics.get('mrecall'):.4f}\",\n",
    "                                f'Precision@{k}': f\"{metrics.get('mprecision'):.4f}\",\n",
    "                                f'F1@{k}': f\"{metrics.get('mf1'):.4f}\" ,\n",
    "                                f'NDCG@{k}': f\"{metrics.get('mndcg'):.4f}\",  \n",
    "                                f'MRR@{k}': f\"{metrics.get('mrr'):.4f}\",\n",
    "                                f'MAP@{k}': f\"{metrics.get('map'):.4f}\"\n",
    "                                         \n",
    "                            }\n",
    "                            data.append(row)\n",
    "                else:\n",
    "                    metrics = model['metrics'] \n",
    "                    row = {\n",
    "                            'dataset': key_dataset,\n",
    "                            'data_strategy': key_data_strategy, \n",
    "                            'RS_strategy': key_RS_strategy,\n",
    "                            'model': key_model,\n",
    "                            'embeddind_model': None,\n",
    "                            'nb_neighbours_asked': None,\n",
    "                            'nb_neighbours_mean': None,\n",
    "                            f'Recall@{k}': f\"{metrics.get('mrecall'):.4f}\",\n",
    "                            f'Precision@{k}': f\"{metrics.get('mprecision'):.4f}\",\n",
    "                            f'F1@{k}': f\"{metrics.get('mf1'):.4f}\" ,\n",
    "                            f'NDCG@{k}': f\"{metrics.get('mndcg'):.4f}\",  \n",
    "                            f'MRR@{k}': f\"{metrics.get('mrr'):.4f}\",\n",
    "                            f'MAP@{k}': f\"{metrics.get('map'):.4f}\"          \n",
    "                        }\n",
    "                    data.append(row)\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "evaluation_results = pd.DataFrame(data)\n",
    "evaluation_results['nb_neighbours_asked'] = evaluation_results['nb_neighbours_asked'].astype('Int64')\n",
    "# evaluation_results['nb_neighbours_mean'] = evaluation_results['nb_neighbours_mean'].astype('Float64')\n",
    "\n",
    "# Function to highlight the best row\n",
    "def highlight_best(row):\n",
    "    subset = evaluation_results[(evaluation_results['dataset'] == row['dataset']) & (evaluation_results['data_strategy'] == row['data_strategy']) & (evaluation_results['RS_strategy'] == row['RS_strategy']) & (evaluation_results['model'] == row['model'])]\n",
    "    max_ndcg = subset[f'NDCG@{k}'].max()\n",
    "    max_mrr = subset[f'MRR@{k}'].max()\n",
    "    max_map = subset[f'MAP@{k}'].max()\n",
    "    # if row[f'NDCG@{k}'] == max_ndcg and row[f'MRR@{k}'] == max_mrr and row[f'MAP@{k}'] == max_map:\n",
    "    if row[f'NDCG@{k}'] == max_ndcg:\n",
    "        return ['background-color: lightblue']*len(row)\n",
    "    return ['']*len(row)\n",
    "\n",
    "# Apply the highlight function\n",
    "styled_evaluation_results = evaluation_results.style.apply(highlight_best, axis=1)\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_evaluation_results\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "evaluation_results.to_csv(evaluation_results_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_evaluation_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lingorank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
