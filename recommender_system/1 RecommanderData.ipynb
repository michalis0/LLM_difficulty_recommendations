{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecommendData\n",
    "\n",
    "The aim of this notebook is to analyse and transform the data from [zeeguu](https://github.com/zeeguu/data-releases.git) so that it can be used by the recommendation model.\n",
    "\n",
    "*First, let's prepare our notebook by importing the necessary libraries and defining the paths to the data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lopilo/.cache/pypoetry/virtualenvs/lingorank-llm-wa__1Cox-py3.9/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lopilo/code/Lingorank_LLM/notebooks\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------- PREPARING NOTEBOOK ---------------------------- #\n",
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd ..\n",
    "\n",
    "# Random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# External modules\n",
    "import os\n",
    "import mysql\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "import time\n",
    "from tqdm import notebook as tqdm\n",
    "import sys\n",
    "\n",
    "# Define PWD as the current git repository\n",
    "import git\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "pwd = repo.working_dir\n",
    "os.chdir(pwd)\n",
    "\n",
    "# Internal modules\n",
    "sys.path.append(pwd)\n",
    "from src.DataManager import DataManager\n",
    "\n",
    "# Set global log level\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download the data\n",
    "\n",
    "Now it's time for us to download the data from **Zeeguu** üòÄ\n",
    "\n",
    "‚ö†Ô∏è **Please note! *Please note that the next two parts of this notebook are particularly long and costly in terms of resources and storage, as they will download the databases, run them on the MySQL server (**which you must have installed**) and finally download them in csv format.* To avoid this waiting time, you can run the next cell, which will download the files already extracted for you. You can then go straight on to part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a9e7fc88ae4f6cb03965f41f14c3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 0 files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/lopilo/code/Lingorank_LLM/data/processed'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------- DOWNLOADING CSVS FROM HUGGINGFACE -------------------- #\n",
    "# Imports\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# Create folder if not exists\n",
    "path = os.path.join(pwd, \"data\", \"processed\")\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Download CSVs\n",
    "snapshot_download(\n",
    "    repo_id=\"OloriBern/FLDE\",\n",
    "    allow_patterns=[\"recommendation/*.csv\"],\n",
    "    local_dir=path,\n",
    "    revision=\"main\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, you can always redo everything manually üôÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------- DOWNLOAD DATA ------------------------------ #\n",
    "data_manager = DataManager()\n",
    "data_manager.download(\"recommendation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now going to send the downloaded files to the zeeguu database in **MySQL**. Make sure you have installed **MySQL** and configured the user:\n",
    "- `user` : zeeguu\n",
    "- password : zeeguu\n",
    "\n",
    "Finally, launch the database with the following command:\n",
    "``bash\n",
    "sudo /etc/init.d/mysql restart\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- PUSH DATA TO MYSQL ---------------------------- #\n",
    "data_manager.push_to_mysql()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform the data into dataframes\n",
    "\n",
    "Now that our data is in the **MySQL** database, we can retrieve it and transform it into dataframes for local storage.\n",
    "\n",
    "**Please note**: Give your *SQL* server time to load the data. You should have *50 tables* in your database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- LIST TABLES ------------------------------- #\n",
    "# D√©finition des identifiants de connection\n",
    "host = \"127.0.0.1\"\n",
    "database = \"zeeguu\"\n",
    "user = \"zeeguu\"\n",
    "password = \"zeeguu\"\n",
    "\n",
    "# Connection √† la base de donn√©es\n",
    "db_connection = mysql.connector.connect(\n",
    "    host=host, user=user, password=password, database=database\n",
    ")\n",
    "cursor = db_connection.cursor()\n",
    "\n",
    "# Liste des tables\n",
    "tables = []\n",
    "display(Markdown(\"*Waiting for tables to be created...*\"))\n",
    "while len(tables) < 50:\n",
    "    cursor.execute(\"SHOW TABLES\")\n",
    "    tables = pd.DataFrame(cursor.fetchall()).iloc[:, 0]\n",
    "    display(\"{}/50 tables created\".format(len(tables)))\n",
    "    print(\"\", end=\"\\r\")\n",
    "    time.sleep(1)\n",
    "\n",
    "display(Markdown(\"### Some tables in the database\"))\n",
    "display(Markdown(\"There are {} tables in the database\".format(len(tables))))\n",
    "display(Markdown(\"Here are some of them:\"))\n",
    "display(tables.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- TRANSFORM DATA TO CSV -------------------------- #\n",
    "# Cr√©ation du dossier de sortie\n",
    "output_folder = os.path.join(pwd, \"data\", \"processed\", \"recommendation\")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Exportation des tables\n",
    "num_empty_tables = 0\n",
    "for table in tables:\n",
    "    cursor.execute(\"SELECT * FROM {}\".format(table))\n",
    "    value = cursor.fetchall()\n",
    "    if len(value) == 0:\n",
    "        display(Markdown(\"- Table **{}** is empty -> **Skipping...**\".format(table)))\n",
    "        num_empty_tables += 1\n",
    "        continue\n",
    "    df = pd.DataFrame(value)\n",
    "    df.columns = [i[0] for i in cursor.description]\n",
    "    df.to_csv(os.path.join(output_folder, \"{}.csv\".format(table)), index=False)\n",
    "    display(Markdown(\"#### Exported table **{}**\".format(table)))\n",
    "    columns = \", \".join(df.columns)\n",
    "    count = len(df)\n",
    "    display(df.describe().loc[[\"min\", \"max\"]].T)\n",
    "    display(Markdown(\"- **Number of rows**: {}\".format(count)))\n",
    "\n",
    "# Give some information about the export\n",
    "display(\n",
    "    Markdown(\n",
    "        \"**Exportation completed !** (*{}%* of the tables were empty)\".format(\n",
    "            round(num_empty_tables / len(tables) * 100, 2)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Close connection\n",
    "cursor.close()\n",
    "db_connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Transform to Surprise format\n",
    "\n",
    "Now that we have the data available in the correct format, we'll transform it into a format that can be used by the **Surprise** library.\n",
    "We therefore wish to have a dataframe of the form :\n",
    "\n",
    "| user_id | item_id | rating | timestamp |\n",
    "|---------|---------|--------|-----------|\n",
    "\n",
    "### The rating issue\n",
    "\n",
    "Users don't actually assign a score to the article they're reading. So we need to find a way of assessing the relevance of an article to a user. We're going to explore several avenues:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The reader's estimation of difficulty\n",
    "\n",
    "We have a table containing the difficulties estimated by users for each item. Assuming that :\n",
    "- A **1** is too simple,\n",
    "- A **5** is too difficult,\n",
    "- A **3** is the ideal difficulty\n",
    "\n",
    "\n",
    "We can calculate binary ratings: *2 for correctly estimated difficulty, 1 for wrongly estimated difficulty and 0 for no estimation*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Dataset 1 : *Based on difficulty feedback*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>534</td>\n",
       "      <td>2078814</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.667047e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3087</td>\n",
       "      <td>2084647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.667072e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2953</td>\n",
       "      <td>2085687</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.667124e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3966</td>\n",
       "      <td>2054215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.667245e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3966</td>\n",
       "      <td>1935544</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.667246e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  article_id  rating     timestamp\n",
       "1      534     2078814     1.0  1.667047e+09\n",
       "2     3087     2084647     1.0  1.667072e+09\n",
       "3     2953     2085687     2.0  1.667124e+09\n",
       "4     3966     2054215     1.0  1.667245e+09\n",
       "5     3966     1935544     1.0  1.667246e+09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Number of users**: 169"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Number of articles**: 330"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Percentage of positive ratings**: 0.789642333984375%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------- CREATE SUPRISE DATASET -------------------------- #\n",
    "# Importation des donn√©es\n",
    "df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        pwd,\n",
    "        \"data\",\n",
    "        \"processed\",\n",
    "        \"recommendation\",\n",
    "        \"article_difficulty_feedback.csv\",\n",
    "    ),\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "# Mise en forme des donn√©es\n",
    "df = df[[\"user_id\", \"article_id\", \"difficulty_feedback\", \"date\"]]\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"]).astype(int) // 10**9\n",
    "df.sort_values(by=\"date\", inplace=True)\n",
    "df.columns = [\"user_id\", \"article_id\", \"rating\", \"timestamp\"]\n",
    "\n",
    "# Create ratings\n",
    "df[\"rating\"] = (abs(df[\"rating\"] - 3) == 0).astype(int)\n",
    "df[\"rating\"] = df[\"rating\"].replace(2, 1).replace(0, 2)\n",
    "\n",
    "df[\"rating\"][df[\"rating\"] == 2] = 1\n",
    "df[\"rating\"][df[\"rating\"] == 0] = 2\n",
    "\n",
    "# Ajout des 0 pour les utilisateurs qui n'ont pas not√© d'article\n",
    "users = df[\"user_id\"].unique()\n",
    "articles = df[\"article_id\"].unique()\n",
    "all_users = np.repeat(users, len(articles))\n",
    "all_articles = np.tile(articles, len(users))\n",
    "all_ratings = np.zeros(len(all_users))\n",
    "all_timestamps = np.zeros(len(all_users))\n",
    "df_all = pd.DataFrame(\n",
    "    {\n",
    "        \"user_id\": all_users,\n",
    "        \"article_id\": all_articles,\n",
    "        \"rating\": all_ratings,\n",
    "        \"timestamp\": all_timestamps,\n",
    "    }\n",
    ")\n",
    "df = pd.concat([df, df_all], axis=0)\n",
    "\n",
    "# Display and save\n",
    "## Create output folder\n",
    "output_folder = os.path.join(\n",
    "    pwd,\n",
    "    \"results\",\n",
    "    \"recommendation_datasets\",\n",
    ")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "## Save to csv\n",
    "df.to_csv(os.path.join(output_folder, \"dataset_1.csv\"), index=False, sep=\"\\t\")\n",
    "## Display\n",
    "display(Markdown(\"#### Dataset 1 : *Based on difficulty feedback*\"))\n",
    "display(df.head())\n",
    "## Display some information\n",
    "display(Markdown(\"- **Number of users**: {}\".format(len(df[\"user_id\"].unique()))))\n",
    "display(Markdown(\"- **Number of articles**: {}\".format(len(df[\"article_id\"].unique()))))\n",
    "display(\n",
    "    Markdown(\n",
    "        \"- **Percentage of positive ratings**: {}%\".format(\n",
    "            round(df[\"rating\"] > 0).mean() * 100, 2\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The reading time\n",
    "\n",
    "Now we can use another piece of information provided by our dataset: the time it takes each user to read an article.\n",
    "\n",
    "*‚ö†Ô∏è Please note that the dataset creators themselves have stated that this information is unreliable!*\n",
    "\n",
    "---\n",
    "We'll proceed as follows:\n",
    "- Sum the time spent by each user on each article,\n",
    "- Replace abnormal reading times with minimum or maximum estimated reading times,\n",
    "- Normalize reading times for each user,\n",
    "- Calculate scores based on normalized reading times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8671/1920451576.py:15: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  articles_df = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset 2 : *Based on reading session*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>186577</td>\n",
       "      <td>12260799984</td>\n",
       "      <td>1.283281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>257843</td>\n",
       "      <td>7662979180</td>\n",
       "      <td>1.794479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>259567</td>\n",
       "      <td>1532595414</td>\n",
       "      <td>1.026119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>261637</td>\n",
       "      <td>1532595398</td>\n",
       "      <td>1.168712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>263209</td>\n",
       "      <td>3065189513</td>\n",
       "      <td>1.321038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39950685</th>\n",
       "      <td>4088</td>\n",
       "      <td>2250414</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39950686</th>\n",
       "      <td>4088</td>\n",
       "      <td>2253489</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39950687</th>\n",
       "      <td>4088</td>\n",
       "      <td>2233736</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39950688</th>\n",
       "      <td>4088</td>\n",
       "      <td>2240407</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39950689</th>\n",
       "      <td>4088</td>\n",
       "      <td>2240408</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39975918 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  article_id    timestamp    rating\n",
       "0               1      186577  12260799984  1.283281\n",
       "1               1      257843   7662979180  1.794479\n",
       "2               1      259567   1532595414  1.026119\n",
       "3               1      261637   1532595398  1.168712\n",
       "4               1      263209   3065189513  1.321038\n",
       "...           ...         ...          ...       ...\n",
       "39950685     4088     2250414            0  0.000000\n",
       "39950686     4088     2253489            0  0.000000\n",
       "39950687     4088     2233736            0  0.000000\n",
       "39950688     4088     2240407            0  0.000000\n",
       "39950689     4088     2240408            0  0.000000\n",
       "\n",
       "[39975918 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Number of users**: 1885"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Number of articles**: 21194"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lopilo/.cache/pypoetry/virtualenvs/lingorank-llm-wa__1Cox-py3.9/lib/python3.9/site-packages/pandas/core/nanops.py:1479: RuntimeWarning: overflow encountered in cast\n",
      "  return dtype.type(n)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "- **Percentage of positive ratings**: 0.0%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------- CREATE SURPRISE DATASET ------------------------- #\n",
    "\n",
    "# Importation des donn√©es\n",
    "df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        pwd,\n",
    "        \"data\",\n",
    "        \"processed\",\n",
    "        \"recommendation\",\n",
    "        \"user_reading_session.csv\",\n",
    "    ),\n",
    "    index_col=0,\n",
    ")\n",
    "articles_df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        os.getcwd(),\n",
    "        \"Lingorank_LLM\" if not (os.getcwd().endswith(\"Lingorank_LLM\")) else \"\",\n",
    "        \"results\",\n",
    "        \"zeeguu_csvs\",\n",
    "        \"recommendation\",\n",
    "        \"article.csv\",\n",
    "    ),\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "# Mise en forme des donn√©es\n",
    "df = df[[\"user_id\", \"article_id\", \"duration\", \"start_time\"]]\n",
    "df.rename(columns={\"start_time\": \"timestamp\"}, inplace=True)\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"]).astype(int) // 10**9\n",
    "df = df.merge(articles_df[\"word_count\"], left_on=\"article_id\", right_index=True)\n",
    "df = df[df[\"word_count\"].str.isnumeric().astype(bool)].dropna(subset=[\"word_count\"])\n",
    "df[\"word_count\"] = df[\"word_count\"].astype(int)\n",
    "df[\"estimated_reading_time\"] = df[\"word_count\"] / 150  # 150 words per minute\n",
    "df[\"duration\"] = df[\"duration\"] / 60e3\n",
    "df.drop(columns=[\"word_count\"], inplace=True)\n",
    "df[\"article_id\"] = df[\"article_id\"].astype(int)\n",
    "\n",
    "# Somme des temps de lecture par utilisateur et par article\n",
    "df = df.groupby([\"user_id\", \"article_id\"]).sum().reset_index()\n",
    "\n",
    "# Cr√©ation des scores\n",
    "df[\"rating\"] = (df[\"duration\"] / df[\"estimated_reading_time\"]).clip(\n",
    "    upper=1, lower=0\n",
    ") + 1\n",
    "df.drop(columns=[\"duration\", \"estimated_reading_time\"], inplace=True)\n",
    "\n",
    "# Ajout des 0 pour les utilisateurs qui n'ont pas not√© d'article\n",
    "users = df[\"user_id\"].unique()\n",
    "articles = df[\"article_id\"].unique()\n",
    "all_users = np.repeat(users, len(articles))\n",
    "all_articles = np.tile(articles, len(users))\n",
    "all_ratings = np.zeros(len(all_users))\n",
    "df_all = pd.DataFrame(\n",
    "    {\n",
    "        \"user_id\": all_users,\n",
    "        \"article_id\": all_articles,\n",
    "        \"rating\": all_ratings,\n",
    "        \"timestamp\": 0,\n",
    "    }\n",
    ")\n",
    "df = pd.concat([df, df_all], axis=0)\n",
    "\n",
    "# Save and display\n",
    "## Create output folder\n",
    "output_folder = os.path.join(\n",
    "    pwd,\n",
    "    \"results\",\n",
    "    \"recommendation_datasets\",\n",
    ")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "## Save to csv\n",
    "df.to_csv(os.path.join(output_folder, \"dataset_2.csv\"), index=False, sep=\"\\t\")\n",
    "## Display\n",
    "display(Markdown(\"#### Dataset 2 : *Based on reading session*\"))\n",
    "display(df)\n",
    "## Display some information\n",
    "display(Markdown(\"- **Number of users**: {}\".format(len(df[\"user_id\"].unique()))))\n",
    "display(Markdown(\"- **Number of articles**: {}\".format(len(df[\"article_id\"].unique()))))\n",
    "display(\n",
    "    Markdown(\n",
    "        \"- **Percentage of positive ratings**: {}%\".format(\n",
    "            round(df[\"rating\"] > 0).mean() * 100, 2\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the article\n",
    "\n",
    "Finally, in order to obtain what will certainly be our most extensive dataset, we'll create a dataset by applying the following evaluation strategy:\n",
    "- **2** if the user has read and liked the article,\n",
    "- **1** if the user has read the article,\n",
    "- **0** otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Dataset 3 : *Based on user article*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>154</td>\n",
       "      <td>34991</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.521404e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>678</td>\n",
       "      <td>35000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.531392e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>8</td>\n",
       "      <td>35003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.539700e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>528</td>\n",
       "      <td>35009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.639511e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>534</td>\n",
       "      <td>36588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.519331e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36368619</th>\n",
       "      <td>4107</td>\n",
       "      <td>2321082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36368620</th>\n",
       "      <td>4107</td>\n",
       "      <td>2342308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36368621</th>\n",
       "      <td>4107</td>\n",
       "      <td>2343468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36368622</th>\n",
       "      <td>4107</td>\n",
       "      <td>2354941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36368623</th>\n",
       "      <td>4107</td>\n",
       "      <td>2227132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36392981 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  article_id  rating     timestamp\n",
       "30            154       34991     2.0  1.521404e+09\n",
       "43            678       35000     2.0  1.531392e+09\n",
       "49              8       35003     1.0  1.539700e+09\n",
       "58            528       35009     1.0  1.639511e+09\n",
       "119           534       36588     1.0  1.519331e+09\n",
       "...           ...         ...     ...           ...\n",
       "36368619     4107     2321082     0.0  0.000000e+00\n",
       "36368620     4107     2342308     0.0  0.000000e+00\n",
       "36368621     4107     2343468     0.0  0.000000e+00\n",
       "36368622     4107     2354941     0.0  0.000000e+00\n",
       "36368623     4107     2227132     0.0  0.000000e+00\n",
       "\n",
       "[36392981 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Number of users**: 1784"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Number of articles**: 20386"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lopilo/.cache/pypoetry/virtualenvs/lingorank-llm-wa__1Cox-py3.9/lib/python3.9/site-packages/pandas/core/nanops.py:1479: RuntimeWarning: overflow encountered in cast\n",
      "  return dtype.type(n)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "- **Percentage of positive ratings**: 0.0%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------- CREATE SURPRISE DATASET ------------------------- #\n",
    "\n",
    "# Importation des donn√©es\n",
    "df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        pwd,\n",
    "        \"data\",\n",
    "        \"processed\",\n",
    "        \"recommendation\",\n",
    "        \"user_article.csv\",\n",
    "    ),\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "# Mise en forme des donn√©es\n",
    "df = df[[\"user_id\", \"article_id\", \"liked\", \"opened\"]].dropna()\n",
    "df.rename(columns={\"opened\": \"timestamp\"}, inplace=True)\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"]).astype(int) // 10**9\n",
    "df[\"article_id\"] = df[\"article_id\"].astype(int)\n",
    "df[\"rating\"] = df[\"liked\"].astype(int) + 1\n",
    "df.drop(columns=[\"liked\"], inplace=True)\n",
    "df = df[[\"user_id\", \"article_id\", \"rating\", \"timestamp\"]]\n",
    "\n",
    "# Ajout des 0 pour les utilisateurs qui n'ont pas not√© d'article\n",
    "users = df[\"user_id\"].unique()\n",
    "articles = df[\"article_id\"].unique()\n",
    "all_users = np.repeat(users, len(articles))\n",
    "all_articles = np.tile(articles, len(users))\n",
    "all_ratings = np.zeros(len(all_users))\n",
    "all_timestamps = np.zeros(len(all_users))\n",
    "df_all = pd.DataFrame(\n",
    "    {\n",
    "        \"user_id\": all_users,\n",
    "        \"article_id\": all_articles,\n",
    "        \"rating\": all_ratings,\n",
    "        \"timestamp\": all_timestamps,\n",
    "    }\n",
    ")\n",
    "df = pd.concat([df, df_all], axis=0)\n",
    "\n",
    "# Save and display\n",
    "## Create output folder\n",
    "output_folder = os.path.join(\n",
    "    pwd,\n",
    "    \"results\",\n",
    "    \"recommendation_datasets\",\n",
    ")\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "## Save to csv\n",
    "df.to_csv(os.path.join(output_folder, \"dataset_3.csv\"), index=False, sep=\"\\t\")\n",
    "## Display\n",
    "display(Markdown(\"#### Dataset 3 : *Based on user article*\"))\n",
    "display(df)\n",
    "## Display some information\n",
    "display(Markdown(\"- **Number of users**: {}\".format(len(df[\"user_id\"].unique()))))\n",
    "display(Markdown(\"- **Number of articles**: {}\".format(len(df[\"article_id\"].unique()))))\n",
    "display(\n",
    "    Markdown(\n",
    "        \"- **Percentage of positive ratings**: {}%\".format(\n",
    "            round(df[\"rating\"] > 0).mean() * 100, 2\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
