{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "\n",
    "my_seed = 0\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n",
    "from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n",
    "from recommenders.models.deeprec.deeprec_utils import prepare_hparams\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import itertools\n",
    "\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the datasets we want to use\n",
    "lingorank = True\n",
    "ml_100k = False\n",
    "goodreads = False\n",
    "tomplay = False\n",
    "\n",
    "# Create the cold start test dataset\n",
    "cold_start = False\n",
    "\n",
    "#Content-based\n",
    "content_based = False\n",
    "\n",
    "#CF\n",
    "als = False\n",
    "als_params = None\n",
    "\n",
    "bpr = False\n",
    "bpr_params = None\n",
    "\n",
    "lmf = False\n",
    "lmf_params = None\n",
    "\n",
    "cf = als or bpr or lmf # If at least one, we do the CF\n",
    "\n",
    "#LightGCN\n",
    "ada = True\n",
    "bert = False\n",
    "xavier_ada = True\n",
    "xavier_bert = False\n",
    "lightgcn = ada or bert or xavier_ada or xavier_bert # If at least one, we do the LightGCN \n",
    "\n",
    "lightgcn_params = {\n",
    "    'n_layers': list(range(1,21)),\n",
    "    'n': [1],\n",
    "    'lr': [0.001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_user_data(group, test_size):\n",
    "        if len(group) == 1:\n",
    "            return pd.DataFrame(), pd.DataFrame(), group\n",
    "        else:\n",
    "            n = max(1, int(round(len(group) * test_size)))\n",
    "            return group.iloc[:-n], group.iloc[-n:], pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, n=None, test_size=0.2, one_core=False):\n",
    "    # Sort by user_id and timestamp\n",
    "    # df.sort_values(by=['user_id', 'timestamp'], ascending=[True, True], inplace=True)\n",
    "\n",
    "    # Sort by user_id and timestamp\n",
    "    df.sort_values(by=['user_id', 'timestamp'], ascending=[True, True], inplace=True)\n",
    "\n",
    "    \n",
    "\n",
    "    tqdm.pandas(desc=\"Splitting data\")\n",
    "    splits = df.groupby('user_id').progress_apply(lambda x: split_user_data(x, test_size))\n",
    "\n",
    "    # Concatenate the results\n",
    "    train_data = pd.concat([split[0] for split in splits])\n",
    "    test_data = pd.concat([split[1] for split in splits])\n",
    "    other_data = pd.concat([split[2] for split in splits])\n",
    "\n",
    "    # Remove other_data from data by checking user_id and item_id\n",
    "    data = pd.concat([train_data, test_data])\n",
    "    # Reset index\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # Find number of articles in test_data but not in train_data\n",
    "    unique_test_articles = set(test_data['item_id'])\n",
    "    unique_train_articles = set(train_data['item_id'])\n",
    "    unique_articles_in_test_not_train = unique_test_articles - unique_train_articles\n",
    "    num_unique_articles_in_test_not_train = len(unique_articles_in_test_not_train)\n",
    "\n",
    "    # Calculate number of unique user_ids in test_data but not in train_data\n",
    "    unique_test_user_ids = set(test_data['user_id'])\n",
    "    unique_train_user_ids = set(train_data['user_id'])\n",
    "    unique_users_in_test_not_train = unique_test_user_ids - unique_train_user_ids\n",
    "    num_unique_users_in_test_not_train = len(unique_users_in_test_not_train)\n",
    "    num_unique_users_in_other_data = len(other_data['user_id'].unique()) if not other_data.empty else 0\n",
    "    num_unique_articles_in_other_data_not_train = len(other_data[~ other_data['item_id'].isin(unique_train_articles)]['item_id'].unique()) if not other_data.empty else 0\n",
    "\n",
    "    print(f\"Number of articles in test_data but not in train_data: {num_unique_articles_in_test_not_train}\")\n",
    "    print(f\"Number of user_ids in test_data but not in train_data: {num_unique_users_in_test_not_train}\")\n",
    "    print(f\"Number of user_ids in other_data: {num_unique_users_in_other_data}\")\n",
    "    print(f\"Number of articles in other_data but not in train_data: {num_unique_articles_in_other_data_not_train}\")\n",
    "\n",
    "    # Calculate size of test data compared to train data\n",
    "    size_test_data = len(test_data)\n",
    "    size_data = len(train_data) + len(test_data)\n",
    "    percentage_test_data = (size_test_data / size_data) * 100\n",
    "\n",
    "    print(f\"Size of test data: {percentage_test_data:.2f}%\")\n",
    "    print(f\"Size of other data: {len(other_data) / size_data * 100:.2f}%\")\n",
    "    print(f\"Size of all test data: {(size_test_data + len(other_data)) / size_data * 100:.2f}%\")\n",
    "    return train_data, test_data, other_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ids(data, train_data, test_data):\n",
    "    # Create mapping for userIds and itemIds based on train_df\n",
    "    unique_user_ids = train_data['user_id'].unique()\n",
    "    unique_item_ids = train_data['item_id'].unique()\n",
    "\n",
    "    user_id_mapping = {userId: i for i, userId in enumerate(unique_user_ids)}\n",
    "    item_id_mapping = {itemId: i for i, itemId in enumerate(unique_item_ids)}\n",
    "\n",
    "    # Map userIds and itemIds in train_df to new consecutive IDs\n",
    "    train_data['mapped_user_id'] = train_data['user_id'].map(user_id_mapping)\n",
    "    train_data['mapped_item_id'] = train_data['item_id'].map(item_id_mapping)\n",
    "\n",
    "    # Function to map new IDs in test_df and update the mapping accordingly\n",
    "    def map_and_update_id(id_value, current_mapping):\n",
    "        if id_value not in current_mapping:\n",
    "            current_mapping[id_value] = max(current_mapping.values()) + 1\n",
    "        return current_mapping[id_value]\n",
    "\n",
    "    test_data['mapped_user_id'] = test_data['user_id'].apply(lambda x: map_and_update_id(x, user_id_mapping))\n",
    "    test_data['mapped_item_id'] = test_data['item_id'].apply(lambda x: map_and_update_id(x, item_id_mapping))\n",
    "\n",
    "    if data is not None:\n",
    "        data['mapped_user_id'] = data['user_id'].map(user_id_mapping).astype('Int64')\n",
    "        data['mapped_item_id'] = data['item_id'].map(item_id_mapping).astype('Int64')\n",
    "    else:\n",
    "        data = pd.concat([train_data, test_data])\n",
    "    \n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    train_data.reset_index(drop=True, inplace=True)\n",
    "    test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data, train_data, test_data, user_id_mapping, item_id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_LingoRank(strategy: int = 2):\n",
    "    data_full = pd.read_csv(f\"../results/recommendation/Zeegu/strategy{strategy}.csv\")\n",
    "    \n",
    "    # Rename data_full.article_id as data_full.item_id\n",
    "    data_full.rename(columns={\"article_id\": \"item_id\"}, inplace=True)\n",
    "    ## Remove the articles for which there is no positive rating \n",
    "    # Before removing articles, count the unique articles\n",
    "    original_unique_articles = data_full['item_id'].nunique()\n",
    "\n",
    "    # Identify articles that have maximum rating <= 0\n",
    "    articles_to_remove = data_full.groupby('item_id')['rating'].max()\n",
    "    articles_to_remove = articles_to_remove[articles_to_remove <= 0].index.tolist()\n",
    "    articles_to_remove.append(2223234) # Cannot use it for content-based because content is wrong. So we don't consider it at all\n",
    "\n",
    "    # Remove these articles from data_full\n",
    "    data_full = data_full[~data_full['item_id'].isin(articles_to_remove)]\n",
    "\n",
    "    data = data_full[(data_full['rating'] != 0)].copy()\n",
    "    \n",
    "    train_data, test_data, other_data = train_test_split(data)\n",
    "    print(f\"Strategy {strategy} - Proportion of positive ratings affected to test set: {round(len(test_data)/(len(test_data)+len(train_data))*100,2)} %\")\n",
    "\n",
    "    data, train_data, test_data, user_id_mapping, item_id_mapping = map_ids(data, train_data, test_data)\n",
    "\n",
    "    # Compute the number of unique users and items and print\n",
    "    num_unique_users = data['mapped_user_id'].nunique()\n",
    "    num_unique_items = data['mapped_item_id'].nunique()\n",
    "    print(f\"Number of unique users: {num_unique_users}\")\n",
    "    print(f\"Number of unique items: {num_unique_items}\")\n",
    "    # Print the number of interactions\n",
    "    print(f\"Number of interactions: {len(data)}\")\n",
    "    # Compute sparsity\n",
    "    sparsity = 1 - len(data) / (num_unique_users * num_unique_items)\n",
    "    print(f\"Sparsity: {sparsity:.2%}\")\n",
    "\n",
    "\n",
    "    ##### Load embeddings #####\n",
    "\n",
    "    items_embeddings = None\n",
    "    if ada or bert or content_based:\n",
    "        items_embeddings = {}\n",
    "        embeddings_file = f\"../results/recommendation/embeddings_strategy{strategy}.csv.gz\"\n",
    "\n",
    "        embedding_models = {\"ada\": ada, \"bert\": bert}\n",
    "        if content_based:\n",
    "            embedding_models = {\"ada\": True, \"bert\": True}\n",
    "\n",
    "        df = pd.read_csv(embeddings_file)\n",
    "        df = df.rename(columns={'id': 'item_id'})\n",
    "        # Iterate over the dictionary\n",
    "        for embedding_model, is_enabled in embedding_models.items():\n",
    "            if not is_enabled:\n",
    "                continue\n",
    "\n",
    "            embedding_key = embedding_model + \"_embedding\"\n",
    "            # Remove rows for which ada_embedding is null\n",
    "            assert data[data['item_id'].isin(df[df[embedding_key].isnull()]['item_id'])].empty # Already removed the article\n",
    "            assert data_full[data_full['item_id'].isin(df[df[embedding_key].isnull()]['item_id'])].empty # Already removed the article\n",
    "            \n",
    "            df2 = df[~ df[embedding_key].isnull()]\n",
    "            df2 = df2.rename(columns={embedding_key: 'embedding'})\n",
    "            df2['embedding'] = df2['embedding'].apply(ast.literal_eval) #Convert list stored as a str to real list type\n",
    "            df2['mapped_item_id'] = df2['item_id'].map(item_id_mapping).astype('Int64')\n",
    "            df2 = df2.dropna(subset=['mapped_item_id']) # If NA, item is not in train set nor test set\n",
    "            items_embeddings[embedding_model] = df2[['item_id', 'mapped_item_id', 'embedding']]\n",
    "\n",
    "    ###########################\n",
    "\n",
    "    return {\n",
    "            'data': data,\n",
    "            'train_data': train_data,\n",
    "            'test_data': test_data,\n",
    "            'user_id_mapping': user_id_mapping,\n",
    "            'item_id_mapping': item_id_mapping,\n",
    "            'items_embeddings': items_embeddings\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(recommendations, real_items, k):\n",
    "    \"\"\"\n",
    "    Compute NDCG at rank k\n",
    "    \"\"\"\n",
    "    ranked_list = [1 if item_id in real_items else 0 for item_id in recommendations]\n",
    "    num_relevant = min(k, len(real_items))\n",
    "    ideal_list = [1] * num_relevant + [0] * (k - num_relevant)\n",
    "    dcg = sum((2 ** rel - 1) / np.log2(idx + 2) for idx, rel in enumerate(ranked_list[:k]))\n",
    "    idcg = sum((2 ** rel - 1) / np.log2(idx + 2) for idx, rel in enumerate(ideal_list[:k]))\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def mrr_at_k(recommendations, real_items, k):\n",
    "    \"\"\"\n",
    "    Compute MRR at rank k\n",
    "    \"\"\"\n",
    "    ranked_list = [1 if item_id in real_items else 0 for item_id in recommendations]\n",
    "    for idx, rel in enumerate(ranked_list[:k]):\n",
    "        if rel > 0:\n",
    "            return 1 / (idx + 1)\n",
    "    return 0\n",
    "\n",
    "def precision_at_k(recommendations, real_items, k):\n",
    "    \"\"\"\n",
    "    Compute Precision at rank k\n",
    "    \"\"\"\n",
    "    return sum([1 if item_id in real_items else 0 for item_id in recommendations[:k]]) / min(k, len(recommendations))\n",
    "\n",
    "def recall_at_k(recommendations, real_items, k):\n",
    "    \"\"\"\n",
    "    Compute Recall at rank k\n",
    "    \"\"\"\n",
    "    return sum([1 if item_id in real_items else 0 for item_id in recommendations[:k]]) / len(real_items)\n",
    "\n",
    "def f1_at_k(precision_at_k, recall_at_k):\n",
    "    \"\"\"\n",
    "    Compute F1 at rank k\n",
    "    \"\"\"\n",
    "    if precision_at_k == 0 and recall_at_k == 0:\n",
    "        return 0\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * (precision_at_k * recall_at_k) / (precision_at_k + recall_at_k)\n",
    "    return f1_score\n",
    "\n",
    "def average_precision_at_k(recommendations, test_items, k):\n",
    "\n",
    "    recommendations_presence = [1 if item_id in test_items else 0 for item_id in recommendations[:k]]\n",
    "\n",
    "    # Keep track of the number of relevant items found\n",
    "    num_relevant = 0\n",
    "    # Keep track of the sum of precisions\n",
    "    sum_precisions = 0\n",
    "    # We are interested in the precision at each point a relevant document is retrieved\n",
    "    for idx in range(min(k, len(recommendations_presence))):\n",
    "        # Check if the item is relevant\n",
    "        if recommendations_presence[idx] == 1:\n",
    "            # Increment the count of relevant items\n",
    "            num_relevant += 1\n",
    "            # Update the sum of precisions\n",
    "            sum_precisions += num_relevant / (idx + 1)\n",
    "\n",
    "    return sum_precisions / min(k, len(test_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_data, data_full, data_strategy, RS_strategy_name, RS_strategy, model_name, model, dataset, k=5, progress=True):\n",
    "\n",
    "    global user_embedding\n",
    "    global item_embeddings\n",
    "    \n",
    "    ndcgs = []\n",
    "    rrs = []\n",
    "    aps = []  \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    all_recommendations = []\n",
    "    all_really_in_test = []\n",
    "\n",
    "    # Loop for each user in test_df\n",
    "    if RS_strategy_name==\"CF\" and data_strategy==\"implicit\" or True:\n",
    "        user_ids = test_data['mapped_user_id'].unique()\n",
    "    else:\n",
    "        user_ids = test_data['user_id'].unique()\n",
    "\n",
    "    if progress:\n",
    "        user_ids_for_loop = tqdm(user_ids, desc=\"Users\")\n",
    "    else:\n",
    "        user_ids_for_loop = user_ids   \n",
    "    for user in user_ids_for_loop:\n",
    "\n",
    "        if RS_strategy_name==\"CF\" and data_strategy==\"implicit\":\n",
    "            top_k_recommendations = model['model'].recommend(user, RS_strategy['user_item_train_data'][user], k)[0]\n",
    "            user_test_items = test_data[test_data['mapped_user_id'] == user].mapped_item_id.tolist()\n",
    "            \n",
    "        elif RS_strategy_name==\"content-based\":\n",
    "\n",
    "            top_k_recommendations = np.array(model['sim_matrix'].loc[user].sort_values(ascending=False).index.tolist()[:k])\n",
    "            user_test_items = test_data[test_data['mapped_user_id'] == user].mapped_item_id.tolist()\n",
    "\n",
    "        elif RS_strategy_name==\"graph-based\":\n",
    "\n",
    "            top_k_recommendations = model['model'].recommend_k_items(pd.DataFrame({'userID': [user]}), top_k=k, remove_seen=True)\n",
    "        \n",
    "            top_k_recommendations = top_k_recommendations['itemID'].tolist()\n",
    "            user_test_items = test_data[test_data['mapped_user_id'] == user].mapped_item_id.tolist()\n",
    "\n",
    "        ndcg = ndcg_at_k(top_k_recommendations, user_test_items, k)\n",
    "        rr = mrr_at_k(top_k_recommendations, user_test_items, k)\n",
    "        ap = average_precision_at_k(top_k_recommendations, user_test_items, k)\n",
    "        precision = precision_at_k(top_k_recommendations, user_test_items, k)\n",
    "        recall = recall_at_k(top_k_recommendations, user_test_items, k)\n",
    "        f1 = f1_at_k(precision, recall)\n",
    "    \n",
    "        ndcgs.append(ndcg)\n",
    "        rrs.append(rr)\n",
    "        aps.append(ap)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    mndcg = np.mean(ndcgs)\n",
    "    mrr = np.mean(rrs)\n",
    "    map = np.mean(aps)\n",
    "    mprecision = np.mean(precisions)\n",
    "    mrecall = np.mean(recalls)\n",
    "    mf1 = np.mean(f1s)\n",
    "\n",
    "    return {\n",
    "        'mndcg': mndcg,\n",
    "        'mrr': mrr,\n",
    "        'map': map,\n",
    "        'mrecall': mrecall,\n",
    "        'mprecision': mprecision,\n",
    "        'mf1': mf1,\n",
    "        'ndcgs': ndcgs,\n",
    "        'rrs': rrs,\n",
    "        'aps': aps,\n",
    "        'recalls': recalls,\n",
    "        'precisions': precisions,\n",
    "        'f1s': f1s,\n",
    "        'all_recommendations': all_recommendations,\n",
    "        'all_really_in_test': all_really_in_test\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "# 1. LingoRank\n",
    "if lingorank:\n",
    "    datasets['LingoRank'] = {}\n",
    "    datasets['LingoRank']['implicit'] = load_LingoRank()\n",
    "    assert set(datasets['LingoRank']['implicit']['data'].dropna(subset=['mapped_user_id'])['mapped_user_id'].astype(int)) == set(range(int(datasets['LingoRank']['implicit']['data']['mapped_user_id'].max()) + 1)), \"User IDs are not continuous and ordered.\"\n",
    "    assert set(datasets['LingoRank']['implicit']['data'].dropna(subset=['mapped_item_id'])['mapped_item_id'].astype(int)) == set(range(int(datasets['LingoRank']['implicit']['data']['mapped_item_id'].max()) + 1)), \"Item IDs are not continuous and ordered.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the structure of our dict\n",
    "def display_keys(d, indent=0):\n",
    "    for key, value in d.items():\n",
    "        print('  ' * indent + str(key))\n",
    "        if isinstance(value, dict) and key != \"user_id_mapping\" and key != \"item_id_mapping\":\n",
    "            display_keys(value, indent+1)\n",
    "\n",
    "display_keys(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key_dataset, dataset in tqdm(datasets.items()):\n",
    "    dataset['implicit']['RS_strategy'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cf:\n",
    "    # Create user-item sparse matrix\n",
    "    for key_dataset, dataset in tqdm(datasets.items()):\n",
    "        dataset['implicit']['RS_strategy']['CF'] = {}\n",
    "        cf = dataset['implicit']['RS_strategy']['CF']\n",
    "        train_data = dataset['implicit']['train_data']\n",
    "\n",
    "        cf['user_item_train_data'] = sparse.csr_matrix(\n",
    "            (train_data['rating'].astype(float), (train_data['mapped_user_id'], train_data['mapped_item_id']))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User embeddings\n",
    "def compute_user_embeddings(train_data, embeddings_df, n):\n",
    "    # Group train_data by user_id and sort by timestamp\n",
    "    train_data_sorted = train_data.sort_values(by=['mapped_user_id', 'timestamp'], ascending=[True, False])\n",
    "    train_data_grouped = train_data_sorted.groupby('mapped_user_id')\n",
    "\n",
    "    # Initialize empty DataFrame to store user embeddings\n",
    "    user_embeddings = pd.DataFrame(columns=['mapped_user_id', 'embedding', 'num_items'])\n",
    "\n",
    "    real_nb_neigh = []\n",
    "    # Iterate through each user in train_data\n",
    "    for user_id, user_data in train_data_grouped:\n",
    "        # Get the last n articles the user interacted with\n",
    "        item_ids = user_data['mapped_item_id'].head(n).tolist()\n",
    "        real_nb_neigh.append(len(item_ids))\n",
    "\n",
    "        # Get the embeddings for these articles\n",
    "        item_embeddings = np.stack(embeddings_df[embeddings_df['mapped_item_id'].isin(item_ids)]['embedding'])\n",
    "\n",
    "        # Compute the mean embedding for the user\n",
    "        user_embedding = np.mean(item_embeddings, axis=0)\n",
    "\n",
    "        # Add the user embedding to the DataFrame\n",
    "        num_items = len(item_embeddings)\n",
    "        user_embeddings.loc[len(user_embeddings)] = [user_id, user_embedding, num_items]\n",
    "\n",
    "    real_nb_neigh = sum(real_nb_neigh)/len(real_nb_neigh)\n",
    "\n",
    "    return user_embeddings, real_nb_neigh\n",
    "\n",
    "def compute_similarity_matrix(items_embeddings, users_embeddings):\n",
    "    # Convert the embeddings to numpy arrays\n",
    "    item_embeddings_array = np.vstack(items_embeddings['embedding'].apply(np.array))\n",
    "    user_embeddings_array = np.vstack(users_embeddings['embedding'].apply(np.array))\n",
    "\n",
    "    # Compute the cosine similarity matrix\n",
    "    cosine_sim_matrix = cosine_similarity(user_embeddings_array, item_embeddings_array)\n",
    "\n",
    "    # Convert the cosine similarity matrix into a DataFrame\n",
    "    # Use user_ids for the index and item_ids for the columns\n",
    "    cosine_sim_df = pd.DataFrame(cosine_sim_matrix,\n",
    "                                index=users_embeddings['mapped_user_id'],\n",
    "                                columns=items_embeddings['mapped_item_id'])\n",
    "    \n",
    "    return cosine_sim_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_init(self, hparams, data, initial_embeddings=None ,seed=None):\n",
    "    \n",
    "    \"\"\"Initializing the model. Create parameters, placeholders, embeddings and loss function.\n",
    "\n",
    "    Args:\n",
    "        hparams (HParams): A HParams object, hold the entire set of hyperparameters.\n",
    "        data (object): A recommenders.models.deeprec.DataModel.ImplicitCF object, load and process data.\n",
    "        seed (int): Seed.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    self.data = data\n",
    "    self.epochs = hparams.epochs\n",
    "    self.lr = hparams.learning_rate\n",
    "    self.emb_dim = hparams.embed_size\n",
    "    self.batch_size = hparams.batch_size\n",
    "    self.n_layers = hparams.n_layers\n",
    "    self.decay = hparams.decay\n",
    "    self.eval_epoch = hparams.eval_epoch\n",
    "    self.top_k = hparams.top_k\n",
    "    self.save_model = hparams.save_model\n",
    "    self.save_epoch = hparams.save_epoch\n",
    "    self.metrics = hparams.metrics\n",
    "    self.model_dir = hparams.MODEL_DIR\n",
    "    self.initial_embeddings = initial_embeddings\n",
    "\n",
    "    metric_options = [\"map\", \"ndcg\", \"precision\", \"recall\"]\n",
    "    for metric in self.metrics:\n",
    "        if metric not in metric_options:\n",
    "            raise ValueError(\n",
    "                \"Wrong metric(s), please select one of this list: {}\".format(\n",
    "                    metric_options\n",
    "                )\n",
    "            )\n",
    "\n",
    "    self.norm_adj = data.get_norm_adj_mat()\n",
    "\n",
    "    self.n_users = data.n_users\n",
    "    self.n_items = data.n_items\n",
    "\n",
    "    self.users = tf.compat.v1.placeholder(tf.int32, shape=(None,))\n",
    "    self.pos_items = tf.compat.v1.placeholder(tf.int32, shape=(None,))\n",
    "    self.neg_items = tf.compat.v1.placeholder(tf.int32, shape=(None,))\n",
    "\n",
    "    self.weights = self._init_weights()\n",
    "    self.ua_embeddings, self.ia_embeddings = self._create_lightgcn_embed()\n",
    "\n",
    "    self.u_g_embeddings = tf.nn.embedding_lookup(\n",
    "        params=self.ua_embeddings, ids=self.users\n",
    "    )\n",
    "    self.pos_i_g_embeddings = tf.nn.embedding_lookup(\n",
    "        params=self.ia_embeddings, ids=self.pos_items\n",
    "    )\n",
    "    self.neg_i_g_embeddings = tf.nn.embedding_lookup(\n",
    "        params=self.ia_embeddings, ids=self.neg_items\n",
    "    )\n",
    "    self.u_g_embeddings_pre = tf.nn.embedding_lookup(\n",
    "        params=self.weights[\"user_embedding\"], ids=self.users\n",
    "    )\n",
    "    self.pos_i_g_embeddings_pre = tf.nn.embedding_lookup(\n",
    "        params=self.weights[\"item_embedding\"], ids=self.pos_items\n",
    "    )\n",
    "    self.neg_i_g_embeddings_pre = tf.nn.embedding_lookup(\n",
    "        params=self.weights[\"item_embedding\"], ids=self.neg_items\n",
    "    )\n",
    "\n",
    "    self.batch_ratings = tf.matmul(\n",
    "        self.u_g_embeddings,\n",
    "        self.pos_i_g_embeddings,\n",
    "        transpose_a=False,\n",
    "        transpose_b=True,\n",
    "    )\n",
    "\n",
    "    self.mf_loss, self.emb_loss = self._create_bpr_loss(\n",
    "        self.u_g_embeddings, self.pos_i_g_embeddings, self.neg_i_g_embeddings\n",
    "    )\n",
    "    self.loss = self.mf_loss + self.emb_loss\n",
    "\n",
    "    self.opt = tf.compat.v1.train.AdamOptimizer(learning_rate=self.lr).minimize(\n",
    "        self.loss\n",
    "    )\n",
    "    self.saver = tf.compat.v1.train.Saver(max_to_keep=1)\n",
    "\n",
    "    gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
    "    self.sess = tf.compat.v1.Session(\n",
    "        config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)\n",
    "    )\n",
    "    self.sess.run(tf.compat.v1.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_init_weights(self):\n",
    "    \"\"\"Initialize user and item embeddings.\n",
    "\n",
    "    Returns:\n",
    "        dict: With keys `user_embedding` and `item_embedding`, embeddings of all users and items.\n",
    "\n",
    "    \"\"\"\n",
    "    all_weights = dict()\n",
    "    initializer = tf.compat.v1.keras.initializers.VarianceScaling(\n",
    "        scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    if self.initial_embeddings is not None:\n",
    "        all_weights[\"item_embedding\"] = tf.Variable(self.initial_embeddings['item_embedding'], dtype=tf.float32, name=\"item_embedding\")\n",
    "        all_weights[\"user_embedding\"] = tf.Variable(self.initial_embeddings['user_embedding'], dtype=tf.float32, name=\"user_embedding\")\n",
    "        print(\"Using pretrained embeddings.\")\n",
    "    else:\n",
    "        all_weights[\"user_embedding\"] = tf.Variable(\n",
    "            initializer([self.n_users, self.emb_dim]), name=\"user_embedding\"\n",
    "        )\n",
    "        all_weights[\"item_embedding\"] = tf.Variable(\n",
    "            initializer([self.n_items, self.emb_dim]), name=\"item_embedding\"\n",
    "        )\n",
    "        print(\"Using xavier initialization.\")\n",
    "\n",
    "    return all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LightGCN.__init__ = new_init\n",
    "LightGCN._init_weights = new_init_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lightgcn:\n",
    "    for key_dataset, dataset in tqdm(datasets.items()):\n",
    "        \n",
    "        dataset['implicit']['RS_strategy']['graph-based'] = {}\n",
    "        graph_based = dataset['implicit']['RS_strategy']['graph-based']\n",
    "        dataset['implicit']['RS_strategy']['graph-based']['models'] = {}\n",
    "        dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN'] = {}\n",
    "\n",
    "        # dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['method'] = {}\n",
    "        dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['embedding_model'] = {}\n",
    "\n",
    "        print(\"=\"*100)\n",
    "        print(key_dataset)\n",
    "        print(\"=\"*100)\n",
    "\n",
    "        # metrics = {\"Recall\": [], \"Precision\": [], \"F1\": [], \"NDCG\": [], \"MRR\": [], \"MAP\": []} \n",
    "        metrics = {}\n",
    "\n",
    "        embeddings_models = [\"ada\" if (ada or xavier_ada) else None] + [\"bert\" if (bert or xavier_bert) else None]\n",
    "        embedding_models = [embeddings_model for embeddings_model in embeddings_models if embeddings_model is not None]\n",
    "        # for embedding_model in dataset['implicit']['items_embeddings'].keys():\n",
    "        for embedding_model in embedding_models:\n",
    "            dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['embedding_model'][embedding_model] = {}\n",
    "            dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['embedding_model'][embedding_model]['method'] = {}\n",
    "            # if embedding_model==\"bert\": continue\n",
    "            print(\"-\"*100)\n",
    "            print(embedding_model)\n",
    "            print(\"-\"*100)\n",
    "                \n",
    "            for method in [method for method in ['Xavier' if xavier_ada or xavier_bert else None] + ['precomputed' if ada or bert else None] if method is not None]:\n",
    "                print(\"*\"*50)\n",
    "                print(method)\n",
    "                print(\"*\"*50)\n",
    "\n",
    "                dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['embedding_model'][embedding_model]['method'][method] = {}\n",
    "\n",
    "                train_data = dataset['implicit']['train_data'].copy()\n",
    "                train_data = train_data.rename(columns = {'mapped_user_id':'userID', 'mapped_item_id':'itemID'})\n",
    "            \n",
    "                test_data = dataset['implicit']['test_data'].copy()\n",
    "                test_data = test_data.rename(columns = {'mapped_user_id':'userID', 'mapped_item_id':'itemID'})\n",
    "                    \n",
    "                dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['data'] = ImplicitCF(train=train_data, test=test_data, seed=my_seed, col_user='userID', col_item='itemID', col_rating='rating')\n",
    "                data = dataset['implicit']['RS_strategy']['graph-based']['models']['LightGCN']['data']\n",
    "\n",
    "                try:\n",
    "                    embed_size = len(dataset['implicit']['items_embeddings'][embedding_model]['embedding'].iloc[0])\n",
    "                except:\n",
    "                    if xavier_ada:\n",
    "                        embed_size = 1536\n",
    "                    elif xavier_bert:\n",
    "                        embed_size = 768\n",
    "                assert (xavier_ada or ada) and embed_size==1536 or (xavier_bert or bert) and embed_size==768, \"Embedding size is not correct\"\n",
    "                print(f\"Embedding size: {embed_size}\")\n",
    "\n",
    "                if method==\"precomputed\":\n",
    "                    item_embeddings = dataset['implicit']['items_embeddings'][embedding_model]\n",
    "\n",
    "                    item_embeddings = item_embeddings[item_embeddings.mapped_item_id.isin(set(train_data.itemID).union(set(test_data.itemID)))]\n",
    "                    item_embeddings = item_embeddings.sort_values(by='mapped_item_id', ascending=True)\n",
    "                    assert item_embeddings[item_embeddings.mapped_item_id.isin(set(train_data.itemID).union(set(test_data.itemID)))].mapped_item_id.is_monotonic_increasing, 'not ordered by item_id'\n",
    "\n",
    "                    initial_embeddings = {}\n",
    "                    initial_embeddings['item_embedding'] = np.vstack(item_embeddings[item_embeddings.mapped_item_id.isin(set(train_data.itemID).union(test_data.itemID))].embedding.values)\n",
    "                    ns = lightgcn_params['n']\n",
    "                elif method==\"Xavier\":\n",
    "                    initial_embeddings = None\n",
    "                    ns = [None]\n",
    "\n",
    "                total_configs = len(lightgcn_params['n_layers'])*len(ns)*len(lightgcn_params['lr'])\n",
    "                config = 0\n",
    "                for n_layers, n, lr in tqdm(itertools.product(lightgcn_params['n_layers'], ns , lightgcn_params['lr']), total=total_configs):\n",
    "                    \n",
    "                    print(\"^\"*50)    \n",
    "                    print(f\"n_layers: {n_layers} - n: {n} - lr: {lr}\")\n",
    "                    print(\"^\"*50) \n",
    "                    if method==\"precomputed\":\n",
    "                        user_embeddings, real_nb_neigh = compute_user_embeddings(dataset['implicit']['train_data'], item_embeddings, n)\n",
    "                        initial_embeddings['user_embedding'] = np.vstack(user_embeddings[user_embeddings.mapped_user_id.isin(set(train_data.userID))].embedding.values)\n",
    "                \n",
    "\n",
    "                    hparams = prepare_hparams(                          \n",
    "                                learning_rate=lr,\n",
    "                                eval_epoch=10000000,\n",
    "                                top_k=5,\n",
    "                                save_model=False,\n",
    "                                epochs=1,\n",
    "                                save_epoch=1,\n",
    "                                model_type=\"lightgcn\",\n",
    "                                embed_size=embed_size,\n",
    "                                n_layers=n_layers,\n",
    "                                batch_size=1024,\n",
    "                                decay=0.0001,\n",
    "                                metrics=[\"recall\", \"ndcg\", \"precision\", \"map\"],\n",
    "                                MODEL_DIR=\"./tests/resources/deeprec/lightgcn/model/lightgcn_model/\"\n",
    "                                )\n",
    "                \n",
    "                \n",
    "                    best_model = None\n",
    "                    best_ndcg = 0\n",
    "                    tf.compat.v1.set_random_seed(my_seed)\n",
    "                    tf.random.set_seed(my_seed)\n",
    "                    np.random.seed(my_seed)\n",
    "                    random.seed(my_seed)\n",
    "                    model = LightGCN(hparams, data, initial_embeddings=initial_embeddings, seed=my_seed)\n",
    "                    save_path = \"../results/lightgcn_model/best_model\"\n",
    "                    patience_max = 10\n",
    "\n",
    "                    with Timer() as train_time:\n",
    "                        for epoch in range(sys.maxsize):\n",
    "                            model.fit()\n",
    "                            eval_start = time.time()\n",
    "                            recall, ndcg, precision, map = model.run_eval()\n",
    "                            eval_end = time.time()\n",
    "                            eval_time = eval_end - eval_start         \n",
    "                            print(f\"Evaluation time: {eval_time:.1f}s\")\n",
    "                            print(f\"Epoch {epoch} - Recall@5: {recall:.4f} - NDCG@5: {ndcg:.4f} - Precision@5: {precision:.4f} - MAP@5: {map:.4f}\")\n",
    "                            print(\"------------------------\")    \n",
    "                            if ndcg > best_ndcg:\n",
    "                                patience = 0\n",
    "                                best_ndcg = ndcg\n",
    "                                best_epoch = epoch\n",
    "                                model.saver.save(model.sess, save_path)\n",
    "                            else:\n",
    "                                patience += 1\n",
    "                            \n",
    "                            if patience == patience_max:\n",
    "                                print(\"=\"*25 + f\"Best NDCG: {best_ndcg:.4f} at epoch {best_epoch}\" + \"=\"*25)\n",
    "                                break\n",
    "                    print(\"Took {} seconds for training.\".format(train_time.interval))\n",
    "\n",
    "                    model.load(save_path)\n",
    "                    eval_metrics =  evaluate(dataset['implicit']['test_data'], None, 'implicit', 'graph-based', dataset['implicit']['RS_strategy']['graph-based'], 'LightGCN', {'model': model}, key_dataset, k=5)\n",
    "                    \n",
    "                    storing_key = f'{embedding_model}_{method}'\n",
    "                    if storing_key not in metrics.keys():\n",
    "                        metrics[storing_key] = {}\n",
    "                        metrics[storing_key] = {\"Recall\": [], \"Precision\": [], \"F1\": [], \"NDCG\": [], \"MRR\": [], \"MAP\": []} \n",
    "                    metrics[storing_key]['Recall'].append(eval_metrics['mrecall'])\n",
    "                    metrics[storing_key]['Precision'].append(eval_metrics['mprecision'])\n",
    "                    metrics[storing_key]['F1'].append(eval_metrics['mf1'])\n",
    "                    metrics[storing_key]['NDCG'].append(eval_metrics['mndcg'])\n",
    "                    metrics[storing_key]['MRR'].append(eval_metrics['mrr'])\n",
    "                    metrics[storing_key]['MAP'].append(eval_metrics['map'])\n",
    "\n",
    "                    model.sess.close()  # Close the existing session\n",
    "                    tf.compat.v1.Session().close()\n",
    "                    # Reset the default graph\n",
    "                    tf.compat.v1.reset_default_graph()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the NDCG values for each series\n",
    "xavier_ada_ndcg = metrics['ada_Xavier']['NDCG']\n",
    "pretrained_ada_ndcg = metrics['ada_precomputed']['NDCG']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "layers = np.arange(1, len(xavier_ada_ndcg) + 1)\n",
    "\n",
    "# Xavier ADA NDCG series\n",
    "plt.plot(layers, xavier_ada_ndcg, marker='x', linestyle='--', label='Xavier ADA', color='black')\n",
    "\n",
    "# Pretrained ADA NDCG series\n",
    "plt.plot(layers, pretrained_ada_ndcg, marker='x', linestyle='-', label='Pretrained ADA', color='black')\n",
    "\n",
    "# Highlight the best NDCG value for Xavier ADA\n",
    "best_xavier_index = np.argmax(xavier_ada_ndcg)\n",
    "plt.scatter(best_xavier_index + 1, xavier_ada_ndcg[best_xavier_index], color='black',\n",
    "            s=100, edgecolor='black', zorder=5, marker='o')\n",
    "\n",
    "# Highlight the best NDCG value for Pretrained ADA\n",
    "best_pretrained_index = np.argmax(pretrained_ada_ndcg)\n",
    "plt.scatter(best_pretrained_index + 1, pretrained_ada_ndcg[best_pretrained_index], color='black',\n",
    "            s=100, edgecolor='black', zorder=5, marker='o')\n",
    "\n",
    "# Set x-axis ticks to only display integers\n",
    "plt.xticks(layers)\n",
    "plt.xlabel('Number of Layers')\n",
    "plt.ylabel('NDCG@5')\n",
    "plt.title('LightGCN Performance by Number of Layers')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "\n",
    "# Save the figure to a PDF file\n",
    "plt.savefig('ndcg_ada.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lingorank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
