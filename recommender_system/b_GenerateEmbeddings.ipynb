{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from random import shuffle\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    " \n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"] # replace by your own API key\n",
    "# openai.api_key = None\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only one dataset at each run \n",
    "lingorank = True\n",
    "goodreads = False\n",
    "ml_100k = False\n",
    "tomplay = False\n",
    "\n",
    "assert sum([lingorank, goodreads, ml_100k, tomplay]) == 1, \"Cannot select more than one dataset\"\n",
    "\n",
    "ada = False\n",
    "bert = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_api_call_cost(prompt_tokens):   \n",
    "    input_token_cost = 0.0001 / 1000 # per token\n",
    "    return (prompt_tokens * input_token_cost)\n",
    "\n",
    "#Source: https://platform.openai.com/docs/guides/embeddings/use-cases\n",
    "model = \"text-embedding-ada-002\"\n",
    "def get_embedding(text, model=model):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    try:\n",
    "        result = openai.Embedding.create(input = text, model=model)#['data'][0]['embedding']\n",
    "        embedding = result['data'][0]['embedding']\n",
    "        cost = compute_api_call_cost(result['usage']['total_tokens'])\n",
    "    except Exception as e:\n",
    "        print(\"Embedding not generated\")\n",
    "        print(e)\n",
    "        embedding = None\n",
    "        cost = None\n",
    "        result = None\n",
    "\n",
    "    return embedding, cost, result\n",
    "\n",
    "# Initialize variable to keep track of total number of tokens\n",
    "total_tokens = 0\n",
    "encoding = tiktoken.encoding_for_model(model)\n",
    "\n",
    "\n",
    "# Define function to count tokens\n",
    "def count_tokens(text, index):\n",
    "    global total_tokens\n",
    "    tokens = len(encoding.encode(text))\n",
    "    total_tokens += tokens\n",
    "    truncated_text = text\n",
    "    if tokens > 8000:\n",
    "        # print(f\"Warning: Text in row {index} is too long with {tokens} tokens.\")\n",
    "        truncated_text = encoding.decode(encoding.encode(text)[:8000])\n",
    "    return truncated_text\n",
    "\n",
    "def add_ada_embeddings_to_df(df):\n",
    "    # Apply function to content column\n",
    "    df['truncated_content'] = df['content'].apply(lambda x: count_tokens(x, df[df['content'] == x].index[0]))\n",
    "\n",
    "    # Print total number of tokens\n",
    "    print(f\"Total number of tokens: {total_tokens}\")\n",
    "    print(f\"Total estimated cost: ${compute_api_call_cost(total_tokens):.2f}\")\n",
    "\n",
    "    # Apply function to truncated_content column\n",
    "    # df['ada_embedding'], df['cost'], _ = zip(*df['truncated_content'].apply(lambda x: get_embedding(x)))\n",
    "    tqdm.pandas(desc=\"Progress\")\n",
    "    df['ada_embedding'], df['cost'], _ = zip(*df['truncated_content'].progress_apply(lambda x: get_embedding(x)))\n",
    "\n",
    "\n",
    "    # Compute total cost\n",
    "    total_cost = df['cost'].sum()\n",
    "    del df['cost']\n",
    "\n",
    "    print(f\"Total real cost: ${total_cost:.2f}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(lst):\n",
    "    # Convert each element to string and join with comma\n",
    "    return '[' + ', '.join(map(str, lst)) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(text, model):\n",
    "    embeddings = model.encode(text)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_BERT_embeddings_to_df(df):\n",
    "\n",
    "    model = SentenceTransformer('sentence-transformers/paraphrase-xlm-r-multilingual-v1')\n",
    "\n",
    "    tqdm.pandas(desc=\"Progress\")\n",
    "    df['bert_embedding'] = df['content'].progress_apply(lambda x: get_bert_embedding(x, model))\n",
    "\n",
    "    df['bert_embedding'] = df['bert_embedding'].apply(list_to_string)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lingorank:\n",
    "    file_path = f\"../results/recommendation/Zeegu/article.csv\"\n",
    "    embeddings_file = f\"../results/recommendation/embeddings_strategy2.csv.gz\" \n",
    "    df = pd.read_csv(file_path)\n",
    "if ml_100k:\n",
    "    file_path = f\"../results/recommendation/ml-100k/items.csv\"\n",
    "    embeddings_file = f\"../results/recommendation/embeddings_ml-100k.csv.gz\"\n",
    "    df = pd.read_csv(file_path)\n",
    "if goodreads:\n",
    "    file_path = f\"../results/recommendation/Goodreads/goodreads_books_children.json.gz\"\n",
    "    embeddings_file = f\"../results/recommendation/embeddings_goodreads_children.csv.gz\"\n",
    "    df = pd.read_json(file_path, lines=True, compression=\"gzip\")\n",
    "if tomplay:\n",
    "    file_path = f\"../results/recommendation/Tomplay/items.csv\"\n",
    "    embeddings_file = f\"../results/recommendation/embeddings_tomplay.csv.gz\"\n",
    "    df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lingorank:\n",
    "    data_full = pd.read_csv(f\"../results/recommendation/Zeegu/strategy2.csv\")\n",
    "        \n",
    "    ## Remove the articles for which there is no positive rating \n",
    "    # Before removing articles, count the unique articles\n",
    "    original_unique_articles = data_full['article_id'].nunique()\n",
    "\n",
    "    # Identify articles that have maximum rating <= 0\n",
    "    articles_to_remove = data_full.groupby('article_id')['rating'].max()\n",
    "    articles_to_remove = articles_to_remove[articles_to_remove <= 0].index.tolist()\n",
    "\n",
    "    # Remove these articles from data_full\n",
    "    data_full = data_full[~data_full['article_id'].isin(articles_to_remove)]\n",
    "\n",
    "    data = data_full[(data_full['rating'] != 0)].copy()\n",
    "\n",
    "    unique_user_ids = data['user_id'].unique()\n",
    "    unique_article_ids = data['article_id'].unique()\n",
    "\n",
    "    df = df[~ df['id'].isnull()]\n",
    "    df = df.copy()\n",
    "    df['id'] = df['id'].astype(int)\n",
    "\n",
    "    # Keep only the articles for which id is in unique_article_ids\n",
    "    df = df[df['id'].isin(unique_article_ids)]\n",
    " \n",
    "    # Convert content stored as bytes to string\n",
    "    # df['content'] = df['content'].apply(lambda x: x[2:-1].encode('utf-8').decode('unicode_escape').encode('latin1').decode('utf-8'))\n",
    "    def format_info(row):\n",
    "        content = row['content']\n",
    "        try:\n",
    "            # Perform the string transformations\n",
    "            formatted_content = content[2:-1].encode('utf-8').decode('unicode_escape').encode('latin1').decode('utf-8')\n",
    "        except Exception as e:\n",
    "            print(f\"Error formatting row: {e}\")\n",
    "            formatted_content = content  # Fallback to original content in case of error\n",
    "        \n",
    "        return formatted_content\n",
    "\n",
    "\n",
    "if ml_100k: \n",
    "    \n",
    "    def format_info(row):\n",
    "        # Format release date\n",
    "        release_date = f\"{row['release date']}\"\n",
    "        \n",
    "        # Extract and format genres\n",
    "        genre_columns = ['unknown', 'Action', 'Adventure', 'Animation', \"Children's\",\n",
    "                        'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir',\n",
    "                        'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', \n",
    "                        'War', 'Western']\n",
    "        genres = [genre for genre in genre_columns if row[genre] == 1]\n",
    "        formatted_genres = ', '.join(genres) if genres else 'N/A'\n",
    "\n",
    "        # Format the information string\n",
    "        info = (\n",
    "            f\"Title: {row['movie title']}\\n\"\n",
    "            f\"Summary: {row['Summary']}\\n\"\n",
    "            f\"Release Date: {release_date}\\n\"\n",
    "            f\"Cast: {row['Cast']}\\n\"\n",
    "            f\"Director: {row['Director']}\\n\"\n",
    "            f\"Genres: {formatted_genres}\\n\"\n",
    "            f\"Runtime: {row['Runtime']}\\n\"\n",
    "            f\"Rating: {row['Rating']}\\n\"\n",
    "            f\"No. of Ratings: {row['No. of ratings']}\"\n",
    "        )\n",
    "        return info\n",
    "\n",
    "if goodreads:\n",
    "\n",
    "    def try_convert_to_int(value):\n",
    "        try:\n",
    "            return int(value)\n",
    "        except (ValueError, TypeError):\n",
    "            return np.nan\n",
    "            \n",
    "    def format_info(row):\n",
    "        \n",
    "        day = try_convert_to_int(row['publication_day'])\n",
    "        month = try_convert_to_int(row['publication_month'])\n",
    "        year = try_convert_to_int(row['publication_year'])\n",
    "\n",
    "        date = f\"{day}/{month}/{year}\" if not np.isnan(day) and not np.isnan(month) and not np.isnan(year) else np.nan\n",
    "        info = (\n",
    "            f\"Title: {row['title']}\\n\"\n",
    "            f\"Description: {row['description']}\\n\"\n",
    "            f\"Date: {date}\\n\"\n",
    "            f\"Publisher: {row['publisher']}\\n\"\n",
    "            f\"Format: {row['format']}\\n\"\n",
    "            f\"Number of Pages: {row['num_pages']}\\n\"\n",
    "            f\"Text Reviews Count: {row['text_reviews_count']}\\n\"\n",
    "            f\"Country Code: {row['country_code']}\\n\"\n",
    "            f\"Language Code: {row['language_code']}\\n\"\n",
    "            f\"Average Rating: {row['average_rating']}\\n\"\n",
    "            f\"Ratings Count: {row['ratings_count']}\"\n",
    "        \n",
    "        )\n",
    "        return info\n",
    "        \n",
    "if tomplay:\n",
    "    def format_info(row):\n",
    "        info = (\n",
    "            f\"Titre: {row['NAME']}\\n\"\n",
    "            f\"Compositeur: {row['COMPOSER']}\\n\"\n",
    "            f\"Style: {row['STYLE']}\\n\"\n",
    "            f\"Accompagnement: {row['ACC_TYPE']}\\n\"\n",
    "            f\"Niveau: {row['LEVEL']}\\n\"\n",
    "            f\"Instruments: {row['INSTRUMENT']}\\n\"\n",
    "        )\n",
    "        return info\n",
    "\n",
    "\n",
    "# Apply the function to each row\n",
    "df['content'] = df.apply(format_info, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ada:\n",
    "    df = add_ada_embeddings_to_df(df)\n",
    "if bert:\n",
    "    df = add_BERT_embeddings_to_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_save=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(embeddings_file, index=False, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lingorank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
